{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Rough Draft "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Development and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/pre_processed_data_5_clusters_with_PIE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>PIE_2018</th>\n",
       "      <th>PIE_2017</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MIN_2017</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FT%</th>\n",
       "      <th>TOV</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PF</th>\n",
       "      <th>FP</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "      <th>+/-</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Draft_Number</th>\n",
       "      <th>%_Box_Outs_Off</th>\n",
       "      <th>%_Box_Outs_Def</th>\n",
       "      <th>%_Team_RebWhen_Box_Out</th>\n",
       "      <th>%_Player_RebWhen_Box_Out</th>\n",
       "      <th>ContestedREB%</th>\n",
       "      <th>DeferredREB_Chances</th>\n",
       "      <th>AdjustedREB_Chance%</th>\n",
       "      <th>AVG_REBDistance</th>\n",
       "      <th>PassesMade</th>\n",
       "      <th>PassesReceived</th>\n",
       "      <th>SecondaryAST</th>\n",
       "      <th>ASTAdj</th>\n",
       "      <th>AST_ToPass%_Adj</th>\n",
       "      <th>ScreenAssists_PTS</th>\n",
       "      <th>Deflections</th>\n",
       "      <th>%_Loose_BallsRecovered_OFF</th>\n",
       "      <th>%_Loose_BallsRecovered_DEF</th>\n",
       "      <th>ChargesDrawn</th>\n",
       "      <th>Contested2PT_Shots</th>\n",
       "      <th>Contested3PT_Shots</th>\n",
       "      <th>FGM_und_5ft</th>\n",
       "      <th>FG%_und_5ft</th>\n",
       "      <th>FGM_5_9ft</th>\n",
       "      <th>FG%_5_9ft</th>\n",
       "      <th>FGM_10_14ft</th>\n",
       "      <th>FG%_10_14ft</th>\n",
       "      <th>FGM_15_19ft</th>\n",
       "      <th>FG%_15_19ft</th>\n",
       "      <th>OPP_FGM_und_5ft</th>\n",
       "      <th>OPP_FG%_und_5ft</th>\n",
       "      <th>OPP_FGM_5_9ft</th>\n",
       "      <th>OPP_FG%_5_9ft</th>\n",
       "      <th>OPP_FGM_10_14ft</th>\n",
       "      <th>OPP_FG%_10_14ft</th>\n",
       "      <th>OPP_FGM_15_19ft</th>\n",
       "      <th>OPP_FG%_15_19ft</th>\n",
       "      <th>OPP_FGM_20_24ft</th>\n",
       "      <th>OPP_FG%_20_24ft</th>\n",
       "      <th>OPP_FGM_25_29ft</th>\n",
       "      <th>OPP_FG%_25_29ft</th>\n",
       "      <th>DEFRTG</th>\n",
       "      <th>NETRTG</th>\n",
       "      <th>AST%</th>\n",
       "      <th>OREB%</th>\n",
       "      <th>DREB%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>TS%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>PACE</th>\n",
       "      <th>cluster_five_1</th>\n",
       "      <th>cluster_five_2</th>\n",
       "      <th>cluster_five_3</th>\n",
       "      <th>cluster_five_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Gordon</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.599522</td>\n",
       "      <td>-1.141838</td>\n",
       "      <td>1.309109</td>\n",
       "      <td>-0.173463</td>\n",
       "      <td>-0.644696</td>\n",
       "      <td>0.749324</td>\n",
       "      <td>1.263600</td>\n",
       "      <td>1.283885</td>\n",
       "      <td>0.203858</td>\n",
       "      <td>1.099042</td>\n",
       "      <td>-0.567144</td>\n",
       "      <td>0.839688</td>\n",
       "      <td>0.782363</td>\n",
       "      <td>1.160474</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>1.284137</td>\n",
       "      <td>1.498676</td>\n",
       "      <td>-0.289077</td>\n",
       "      <td>-0.517186</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.066010</td>\n",
       "      <td>-1.366031</td>\n",
       "      <td>-0.212155</td>\n",
       "      <td>0.414067</td>\n",
       "      <td>-0.371244</td>\n",
       "      <td>0.096483</td>\n",
       "      <td>0.419543</td>\n",
       "      <td>1.052409</td>\n",
       "      <td>1.001736</td>\n",
       "      <td>-0.494928</td>\n",
       "      <td>0.924277</td>\n",
       "      <td>0.489732</td>\n",
       "      <td>-0.095633</td>\n",
       "      <td>0.470303</td>\n",
       "      <td>-0.453438</td>\n",
       "      <td>0.555441</td>\n",
       "      <td>0.260834</td>\n",
       "      <td>0.088749</td>\n",
       "      <td>-0.064828</td>\n",
       "      <td>0.867984</td>\n",
       "      <td>0.674124</td>\n",
       "      <td>-0.259852</td>\n",
       "      <td>1.297981</td>\n",
       "      <td>0.696523</td>\n",
       "      <td>-0.191937</td>\n",
       "      <td>-1.079370</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>-0.129931</td>\n",
       "      <td>0.880296</td>\n",
       "      <td>-0.299786</td>\n",
       "      <td>1.892958</td>\n",
       "      <td>0.514053</td>\n",
       "      <td>1.237220</td>\n",
       "      <td>-0.397844</td>\n",
       "      <td>1.283978</td>\n",
       "      <td>0.104264</td>\n",
       "      <td>1.222654</td>\n",
       "      <td>0.318478</td>\n",
       "      <td>1.134101</td>\n",
       "      <td>0.557654</td>\n",
       "      <td>0.799380</td>\n",
       "      <td>-0.543979</td>\n",
       "      <td>0.425220</td>\n",
       "      <td>-0.257629</td>\n",
       "      <td>-0.053253</td>\n",
       "      <td>0.399981</td>\n",
       "      <td>1.015231</td>\n",
       "      <td>-0.325281</td>\n",
       "      <td>-0.387679</td>\n",
       "      <td>1.066946</td>\n",
       "      <td>0.514631</td>\n",
       "      <td>-0.452034</td>\n",
       "      <td>-0.309475</td>\n",
       "      <td>-0.528777</td>\n",
       "      <td>-0.460259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abdel Nader</td>\n",
       "      <td>6.6</td>\n",
       "      <td>-2.108971</td>\n",
       "      <td>-0.507239</td>\n",
       "      <td>-1.370192</td>\n",
       "      <td>-0.655630</td>\n",
       "      <td>0.284558</td>\n",
       "      <td>-0.998337</td>\n",
       "      <td>-1.406031</td>\n",
       "      <td>-1.539799</td>\n",
       "      <td>0.332523</td>\n",
       "      <td>-1.028178</td>\n",
       "      <td>-1.393695</td>\n",
       "      <td>-0.688977</td>\n",
       "      <td>-1.097853</td>\n",
       "      <td>-0.602416</td>\n",
       "      <td>-1.429079</td>\n",
       "      <td>-1.546621</td>\n",
       "      <td>-0.978165</td>\n",
       "      <td>-0.289077</td>\n",
       "      <td>-0.782997</td>\n",
       "      <td>-0.395047</td>\n",
       "      <td>0.469312</td>\n",
       "      <td>1.313518</td>\n",
       "      <td>0.755544</td>\n",
       "      <td>-0.713131</td>\n",
       "      <td>0.729937</td>\n",
       "      <td>-0.893138</td>\n",
       "      <td>0.109908</td>\n",
       "      <td>-1.339807</td>\n",
       "      <td>1.134127</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>-1.544720</td>\n",
       "      <td>-1.309731</td>\n",
       "      <td>-0.793954</td>\n",
       "      <td>-1.195789</td>\n",
       "      <td>0.169218</td>\n",
       "      <td>-0.977220</td>\n",
       "      <td>-0.786824</td>\n",
       "      <td>-0.182312</td>\n",
       "      <td>0.226036</td>\n",
       "      <td>-1.039099</td>\n",
       "      <td>-1.167553</td>\n",
       "      <td>-0.858718</td>\n",
       "      <td>-1.481704</td>\n",
       "      <td>-2.639338</td>\n",
       "      <td>-0.834231</td>\n",
       "      <td>-1.079370</td>\n",
       "      <td>-1.461559</td>\n",
       "      <td>-1.048082</td>\n",
       "      <td>-1.322837</td>\n",
       "      <td>-2.098175</td>\n",
       "      <td>-1.276536</td>\n",
       "      <td>-0.405605</td>\n",
       "      <td>-1.844887</td>\n",
       "      <td>-2.060737</td>\n",
       "      <td>-1.548192</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>-1.301127</td>\n",
       "      <td>0.279941</td>\n",
       "      <td>-1.232317</td>\n",
       "      <td>1.226359</td>\n",
       "      <td>-1.078475</td>\n",
       "      <td>1.208196</td>\n",
       "      <td>0.186802</td>\n",
       "      <td>-1.334113</td>\n",
       "      <td>-0.676263</td>\n",
       "      <td>-0.393052</td>\n",
       "      <td>-0.346562</td>\n",
       "      <td>-1.616033</td>\n",
       "      <td>-1.748715</td>\n",
       "      <td>-0.360054</td>\n",
       "      <td>0.514631</td>\n",
       "      <td>2.212225</td>\n",
       "      <td>-0.309475</td>\n",
       "      <td>-0.528777</td>\n",
       "      <td>-0.460259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al Horford</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.166145</td>\n",
       "      <td>1.316686</td>\n",
       "      <td>1.145066</td>\n",
       "      <td>0.605933</td>\n",
       "      <td>1.143698</td>\n",
       "      <td>-0.247081</td>\n",
       "      <td>0.670153</td>\n",
       "      <td>0.793366</td>\n",
       "      <td>0.870873</td>\n",
       "      <td>0.102390</td>\n",
       "      <td>0.212669</td>\n",
       "      <td>0.839688</td>\n",
       "      <td>-0.142267</td>\n",
       "      <td>1.564640</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>1.133714</td>\n",
       "      <td>1.455135</td>\n",
       "      <td>-0.289077</td>\n",
       "      <td>1.644977</td>\n",
       "      <td>0.862278</td>\n",
       "      <td>1.047955</td>\n",
       "      <td>-1.510339</td>\n",
       "      <td>-0.175059</td>\n",
       "      <td>0.376987</td>\n",
       "      <td>0.454340</td>\n",
       "      <td>0.800622</td>\n",
       "      <td>0.450934</td>\n",
       "      <td>0.644586</td>\n",
       "      <td>0.944678</td>\n",
       "      <td>-0.274738</td>\n",
       "      <td>1.381629</td>\n",
       "      <td>0.974197</td>\n",
       "      <td>0.433107</td>\n",
       "      <td>1.305268</td>\n",
       "      <td>0.659929</td>\n",
       "      <td>1.530421</td>\n",
       "      <td>0.130764</td>\n",
       "      <td>0.740880</td>\n",
       "      <td>-0.732346</td>\n",
       "      <td>-1.039099</td>\n",
       "      <td>1.868931</td>\n",
       "      <td>1.482431</td>\n",
       "      <td>0.450128</td>\n",
       "      <td>0.783120</td>\n",
       "      <td>1.597877</td>\n",
       "      <td>0.315278</td>\n",
       "      <td>1.056767</td>\n",
       "      <td>-0.037210</td>\n",
       "      <td>0.623365</td>\n",
       "      <td>0.750883</td>\n",
       "      <td>1.012746</td>\n",
       "      <td>-0.405605</td>\n",
       "      <td>0.416510</td>\n",
       "      <td>-0.918397</td>\n",
       "      <td>0.606531</td>\n",
       "      <td>-0.949062</td>\n",
       "      <td>1.083286</td>\n",
       "      <td>-0.906025</td>\n",
       "      <td>0.868527</td>\n",
       "      <td>0.776951</td>\n",
       "      <td>0.532085</td>\n",
       "      <td>-1.586700</td>\n",
       "      <td>-1.060358</td>\n",
       "      <td>1.361408</td>\n",
       "      <td>1.116462</td>\n",
       "      <td>0.489615</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.533201</td>\n",
       "      <td>0.383563</td>\n",
       "      <td>0.090018</td>\n",
       "      <td>-0.992504</td>\n",
       "      <td>-0.452034</td>\n",
       "      <td>-0.309475</td>\n",
       "      <td>-0.528777</td>\n",
       "      <td>2.172691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al-Farouq Aminu</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-0.070697</td>\n",
       "      <td>0.288108</td>\n",
       "      <td>0.943945</td>\n",
       "      <td>0.428992</td>\n",
       "      <td>0.720924</td>\n",
       "      <td>0.042967</td>\n",
       "      <td>0.105758</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.439912</td>\n",
       "      <td>-0.372274</td>\n",
       "      <td>-0.214675</td>\n",
       "      <td>-0.003560</td>\n",
       "      <td>0.971477</td>\n",
       "      <td>0.769501</td>\n",
       "      <td>0.238268</td>\n",
       "      <td>0.527274</td>\n",
       "      <td>1.251245</td>\n",
       "      <td>-0.289077</td>\n",
       "      <td>1.136596</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.066010</td>\n",
       "      <td>-0.925316</td>\n",
       "      <td>0.660380</td>\n",
       "      <td>-0.591655</td>\n",
       "      <td>0.140443</td>\n",
       "      <td>1.310221</td>\n",
       "      <td>0.069715</td>\n",
       "      <td>1.052409</td>\n",
       "      <td>1.144879</td>\n",
       "      <td>-0.552009</td>\n",
       "      <td>-0.032652</td>\n",
       "      <td>-0.342148</td>\n",
       "      <td>-0.095633</td>\n",
       "      <td>-0.223917</td>\n",
       "      <td>-0.555864</td>\n",
       "      <td>1.088569</td>\n",
       "      <td>1.145780</td>\n",
       "      <td>0.054940</td>\n",
       "      <td>-0.028951</td>\n",
       "      <td>-1.039099</td>\n",
       "      <td>1.031839</td>\n",
       "      <td>1.006478</td>\n",
       "      <td>-0.238987</td>\n",
       "      <td>-0.185822</td>\n",
       "      <td>-0.191937</td>\n",
       "      <td>-0.771416</td>\n",
       "      <td>-1.461559</td>\n",
       "      <td>-1.243561</td>\n",
       "      <td>-1.322837</td>\n",
       "      <td>-1.376140</td>\n",
       "      <td>0.644638</td>\n",
       "      <td>-1.921448</td>\n",
       "      <td>1.237220</td>\n",
       "      <td>0.619465</td>\n",
       "      <td>1.116125</td>\n",
       "      <td>-0.518985</td>\n",
       "      <td>1.361144</td>\n",
       "      <td>0.552206</td>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.359065</td>\n",
       "      <td>0.442925</td>\n",
       "      <td>0.279922</td>\n",
       "      <td>-0.470984</td>\n",
       "      <td>0.958301</td>\n",
       "      <td>-1.276797</td>\n",
       "      <td>0.430470</td>\n",
       "      <td>1.104013</td>\n",
       "      <td>-0.278114</td>\n",
       "      <td>-0.517965</td>\n",
       "      <td>-0.767332</td>\n",
       "      <td>-0.367594</td>\n",
       "      <td>-0.452034</td>\n",
       "      <td>-0.309475</td>\n",
       "      <td>1.891156</td>\n",
       "      <td>-0.460259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alan Williams</td>\n",
       "      <td>27.4</td>\n",
       "      <td>-0.101249</td>\n",
       "      <td>-0.223522</td>\n",
       "      <td>-0.996731</td>\n",
       "      <td>-1.904672</td>\n",
       "      <td>-2.098239</td>\n",
       "      <td>-1.900675</td>\n",
       "      <td>-1.082978</td>\n",
       "      <td>-1.192006</td>\n",
       "      <td>-2.124130</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>-0.822873</td>\n",
       "      <td>0.400138</td>\n",
       "      <td>0.782363</td>\n",
       "      <td>-0.602416</td>\n",
       "      <td>1.187900</td>\n",
       "      <td>-0.502385</td>\n",
       "      <td>-0.978165</td>\n",
       "      <td>-0.289077</td>\n",
       "      <td>0.139842</td>\n",
       "      <td>0.212055</td>\n",
       "      <td>1.775629</td>\n",
       "      <td>1.395583</td>\n",
       "      <td>0.297168</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.019047</td>\n",
       "      <td>1.100539</td>\n",
       "      <td>-0.075993</td>\n",
       "      <td>-2.640554</td>\n",
       "      <td>-1.463744</td>\n",
       "      <td>-1.836877</td>\n",
       "      <td>-0.619342</td>\n",
       "      <td>-0.627773</td>\n",
       "      <td>-1.740037</td>\n",
       "      <td>0.069104</td>\n",
       "      <td>0.910691</td>\n",
       "      <td>1.193370</td>\n",
       "      <td>-0.294846</td>\n",
       "      <td>-2.957126</td>\n",
       "      <td>3.466572</td>\n",
       "      <td>-1.039099</td>\n",
       "      <td>-1.455885</td>\n",
       "      <td>-1.246407</td>\n",
       "      <td>-0.772313</td>\n",
       "      <td>-0.400173</td>\n",
       "      <td>1.231358</td>\n",
       "      <td>0.102843</td>\n",
       "      <td>-1.461559</td>\n",
       "      <td>-2.263512</td>\n",
       "      <td>-1.322837</td>\n",
       "      <td>-2.098175</td>\n",
       "      <td>-1.276536</td>\n",
       "      <td>-4.343925</td>\n",
       "      <td>-0.948318</td>\n",
       "      <td>0.982982</td>\n",
       "      <td>-1.172951</td>\n",
       "      <td>1.183131</td>\n",
       "      <td>-1.301127</td>\n",
       "      <td>-0.784603</td>\n",
       "      <td>-1.347304</td>\n",
       "      <td>3.603730</td>\n",
       "      <td>-1.348329</td>\n",
       "      <td>-2.238684</td>\n",
       "      <td>-2.950574</td>\n",
       "      <td>0.052651</td>\n",
       "      <td>0.889189</td>\n",
       "      <td>0.237322</td>\n",
       "      <td>1.768256</td>\n",
       "      <td>-1.945049</td>\n",
       "      <td>-1.528581</td>\n",
       "      <td>0.110191</td>\n",
       "      <td>-0.992504</td>\n",
       "      <td>2.212225</td>\n",
       "      <td>-0.309475</td>\n",
       "      <td>-0.528777</td>\n",
       "      <td>-0.460259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player  PIE_2018  PIE_2017       AGE  MIN_2017        GP  \\\n",
       "0     Aaron Gordon      10.9  0.599522 -1.141838  1.309109 -0.173463   \n",
       "1      Abdel Nader       6.6 -2.108971 -0.507239 -1.370192 -0.655630   \n",
       "2       Al Horford      13.4  1.166145  1.316686  1.145066  0.605933   \n",
       "3  Al-Farouq Aminu       9.7 -0.070697  0.288108  0.943945  0.428992   \n",
       "4    Alan Williams      27.4 -0.101249 -0.223522 -0.996731 -1.904672   \n",
       "\n",
       "          W         L       PTS       FGM       3P%       FTM       FT%  \\\n",
       "0 -0.644696  0.749324  1.263600  1.283885  0.203858  1.099042 -0.567144   \n",
       "1  0.284558 -0.998337 -1.406031 -1.539799  0.332523 -1.028178 -1.393695   \n",
       "2  1.143698 -0.247081  0.670153  0.793366  0.870873  0.102390  0.212669   \n",
       "3  0.720924  0.042967  0.105758  0.006735  0.439912 -0.372274 -0.214675   \n",
       "4 -2.098239 -1.900675 -1.082978 -1.192006 -2.124130 -0.003908 -0.822873   \n",
       "\n",
       "        TOV       STL       BLK        PF        FP       DD2       TD3  \\\n",
       "0  0.839688  0.782363  1.160474  0.082474  1.284137  1.498676 -0.289077   \n",
       "1 -0.688977 -1.097853 -0.602416 -1.429079 -1.546621 -0.978165 -0.289077   \n",
       "2  0.839688 -0.142267  1.564640  0.082474  1.133714  1.455135 -0.289077   \n",
       "3 -0.003560  0.971477  0.769501  0.238268  0.527274  1.251245 -0.289077   \n",
       "4  0.400138  0.782363 -0.602416  1.187900 -0.502385 -0.978165 -0.289077   \n",
       "\n",
       "        +/-    Height    Weight  Draft_Number  %_Box_Outs_Off  %_Box_Outs_Def  \\\n",
       "0 -0.517186  0.531658  0.066010     -1.366031       -0.212155        0.414067   \n",
       "1 -0.782997 -0.395047  0.469312      1.313518        0.755544       -0.713131   \n",
       "2  1.644977  0.862278  1.047955     -1.510339       -0.175059        0.376987   \n",
       "3  1.136596  0.531658  0.066010     -0.925316        0.660380       -0.591655   \n",
       "4  0.139842  0.212055  1.775629      1.395583        0.297168       -0.143675   \n",
       "\n",
       "   %_Team_RebWhen_Box_Out  %_Player_RebWhen_Box_Out  ContestedREB%  \\\n",
       "0               -0.371244                  0.096483       0.419543   \n",
       "1                0.729937                 -0.893138       0.109908   \n",
       "2                0.454340                  0.800622       0.450934   \n",
       "3                0.140443                  1.310221       0.069715   \n",
       "4               -0.019047                  1.100539      -0.075993   \n",
       "\n",
       "   DeferredREB_Chances  AdjustedREB_Chance%  AVG_REBDistance  PassesMade  \\\n",
       "0             1.052409             1.001736        -0.494928    0.924277   \n",
       "1            -1.339807             1.134127         0.033494   -1.544720   \n",
       "2             0.644586             0.944678        -0.274738    1.381629   \n",
       "3             1.052409             1.144879        -0.552009   -0.032652   \n",
       "4            -2.640554            -1.463744        -1.836877   -0.619342   \n",
       "\n",
       "   PassesReceived  SecondaryAST    ASTAdj  AST_ToPass%_Adj  ScreenAssists_PTS  \\\n",
       "0        0.489732     -0.095633  0.470303        -0.453438           0.555441   \n",
       "1       -1.309731     -0.793954 -1.195789         0.169218          -0.977220   \n",
       "2        0.974197      0.433107  1.305268         0.659929           1.530421   \n",
       "3       -0.342148     -0.095633 -0.223917        -0.555864           1.088569   \n",
       "4       -0.627773     -1.740037  0.069104         0.910691           1.193370   \n",
       "\n",
       "   Deflections  %_Loose_BallsRecovered_OFF  %_Loose_BallsRecovered_DEF  \\\n",
       "0     0.260834                    0.088749                   -0.064828   \n",
       "1    -0.786824                   -0.182312                    0.226036   \n",
       "2     0.130764                    0.740880                   -0.732346   \n",
       "3     1.145780                    0.054940                   -0.028951   \n",
       "4    -0.294846                   -2.957126                    3.466572   \n",
       "\n",
       "   ChargesDrawn  Contested2PT_Shots  Contested3PT_Shots  FGM_und_5ft  \\\n",
       "0      0.867984            0.674124           -0.259852     1.297981   \n",
       "1     -1.039099           -1.167553           -0.858718    -1.481704   \n",
       "2     -1.039099            1.868931            1.482431     0.450128   \n",
       "3     -1.039099            1.031839            1.006478    -0.238987   \n",
       "4     -1.039099           -1.455885           -1.246407    -0.772313   \n",
       "\n",
       "   FG%_und_5ft  FGM_5_9ft  FG%_5_9ft  FGM_10_14ft  FG%_10_14ft  FGM_15_19ft  \\\n",
       "0     0.696523  -0.191937  -1.079370     0.784400    -0.129931     0.880296   \n",
       "1    -2.639338  -0.834231  -1.079370    -1.461559    -1.048082    -1.322837   \n",
       "2     0.783120   1.597877   0.315278     1.056767    -0.037210     0.623365   \n",
       "3    -0.185822  -0.191937  -0.771416    -1.461559    -1.243561    -1.322837   \n",
       "4    -0.400173   1.231358   0.102843    -1.461559    -2.263512    -1.322837   \n",
       "\n",
       "   FG%_15_19ft  OPP_FGM_und_5ft  OPP_FG%_und_5ft  OPP_FGM_5_9ft  \\\n",
       "0    -0.299786         1.892958         0.514053       1.237220   \n",
       "1    -2.098175        -1.276536        -0.405605      -1.844887   \n",
       "2     0.750883         1.012746        -0.405605       0.416510   \n",
       "3    -1.376140         0.644638        -1.921448       1.237220   \n",
       "4    -2.098175        -1.276536        -4.343925      -0.948318   \n",
       "\n",
       "   OPP_FG%_5_9ft  OPP_FGM_10_14ft  OPP_FG%_10_14ft  OPP_FGM_15_19ft  \\\n",
       "0      -0.397844         1.283978         0.104264         1.222654   \n",
       "1      -2.060737        -1.548192         0.027315        -1.301127   \n",
       "2      -0.918397         0.606531        -0.949062         1.083286   \n",
       "3       0.619465         1.116125        -0.518985         1.361144   \n",
       "4       0.982982        -1.172951         1.183131        -1.301127   \n",
       "\n",
       "   OPP_FG%_15_19ft  OPP_FGM_20_24ft  OPP_FG%_20_24ft  OPP_FGM_25_29ft  \\\n",
       "0         0.318478         1.134101         0.557654         0.799380   \n",
       "1         0.279941        -1.232317         1.226359        -1.078475   \n",
       "2        -0.906025         0.868527         0.776951         0.532085   \n",
       "3         0.552206         0.957778         0.359065         0.442925   \n",
       "4        -0.784603        -1.347304         3.603730        -1.348329   \n",
       "\n",
       "   OPP_FG%_25_29ft    DEFRTG    NETRTG      AST%     OREB%     DREB%  \\\n",
       "0        -0.543979  0.425220 -0.257629 -0.053253  0.399981  1.015231   \n",
       "1         1.208196  0.186802 -1.334113 -0.676263 -0.393052 -0.346562   \n",
       "2        -1.586700 -1.060358  1.361408  1.116462  0.489615  0.840726   \n",
       "3         0.279922 -0.470984  0.958301 -1.276797  0.430470  1.104013   \n",
       "4        -2.238684 -2.950574  0.052651  0.889189  0.237322  1.768256   \n",
       "\n",
       "       eFG%       TS%      USG%      PACE  cluster_five_1  cluster_five_2  \\\n",
       "0 -0.325281 -0.387679  1.066946  0.514631       -0.452034       -0.309475   \n",
       "1 -1.616033 -1.748715 -0.360054  0.514631        2.212225       -0.309475   \n",
       "2  0.533201  0.383563  0.090018 -0.992504       -0.452034       -0.309475   \n",
       "3 -0.278114 -0.517965 -0.767332 -0.367594       -0.452034       -0.309475   \n",
       "4 -1.945049 -1.528581  0.110191 -0.992504        2.212225       -0.309475   \n",
       "\n",
       "   cluster_five_3  cluster_five_4  \n",
       "0       -0.528777       -0.460259  \n",
       "1       -0.528777       -0.460259  \n",
       "2       -0.528777        2.172691  \n",
       "3        1.891156       -0.460259  \n",
       "4       -0.528777       -0.460259  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389, 77)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## I will use the following Linear Regression Models:\n",
    "statsmodels' OLS\n",
    "Scikit-Learn's Ridge,Lasso, and Elatic Net\n",
    "Scikit-Learn's RandomForest\n",
    "XGBoost's Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split for Statsmodels' OLS Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Explanatory Variables are already appropriately scaled in previous notebook.\n",
    "\n",
    "# splitting training and testing data as welll as adding OLS's required constant variable.\n",
    "\n",
    "X = df.drop(['Player','PIE_2018'], axis=1)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = df.PIE_2018\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the OLS Regression Model\n",
    "\n",
    "# Create the model\n",
    "ols =  sm.OLS(y_train,X_train)\n",
    "# Fit the model with fit() \n",
    "ols = ols.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>PIE_2018</td>     <th>  R-squared:         </th> <td>   0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 30 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>5.76e-26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:50:12</td>     <th>  Log-Likelihood:    </th> <td> -461.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   233</td>      <th>  AIC:               </th> <td>   1075.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   157</td>      <th>  BIC:               </th> <td>   1337.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    75</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                      <td>    9.4626</td> <td>    0.159</td> <td>   59.516</td> <td> 0.000</td> <td>    9.149</td> <td>    9.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PIE_2017</th>                   <td>   -1.8306</td> <td>    1.061</td> <td>   -1.725</td> <td> 0.086</td> <td>   -3.927</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>                        <td>   -0.0978</td> <td>    0.186</td> <td>   -0.526</td> <td> 0.600</td> <td>   -0.465</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MIN_2017</th>                   <td>   -0.2710</td> <td>    2.737</td> <td>   -0.099</td> <td> 0.921</td> <td>   -5.677</td> <td>    5.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GP</th>                         <td>    3.5085</td> <td>    1.103</td> <td>    3.180</td> <td> 0.002</td> <td>    1.329</td> <td>    5.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>W</th>                          <td>   -1.9696</td> <td>    0.878</td> <td>   -2.242</td> <td> 0.026</td> <td>   -3.705</td> <td>   -0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>L</th>                          <td>   -2.8366</td> <td>    0.807</td> <td>   -3.513</td> <td> 0.001</td> <td>   -4.432</td> <td>   -1.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTS</th>                        <td>    6.4535</td> <td>    4.155</td> <td>    1.553</td> <td> 0.122</td> <td>   -1.754</td> <td>   14.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FGM</th>                        <td>   -8.4560</td> <td>    3.851</td> <td>   -2.196</td> <td> 0.030</td> <td>  -16.062</td> <td>   -0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3P%</th>                        <td>   -0.0528</td> <td>    0.234</td> <td>   -0.225</td> <td> 0.822</td> <td>   -0.516</td> <td>    0.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FTM</th>                        <td>   -1.5486</td> <td>    0.971</td> <td>   -1.595</td> <td> 0.113</td> <td>   -3.467</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FT%</th>                        <td>    0.3209</td> <td>    0.353</td> <td>    0.908</td> <td> 0.365</td> <td>   -0.377</td> <td>    1.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOV</th>                        <td>   -0.0298</td> <td>    0.614</td> <td>   -0.049</td> <td> 0.961</td> <td>   -1.243</td> <td>    1.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STL</th>                        <td>   -1.9599</td> <td>    0.698</td> <td>   -2.809</td> <td> 0.006</td> <td>   -3.338</td> <td>   -0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BLK</th>                        <td>   -0.7936</td> <td>    0.437</td> <td>   -1.817</td> <td> 0.071</td> <td>   -1.656</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PF</th>                         <td>   -0.6615</td> <td>    0.391</td> <td>   -1.692</td> <td> 0.093</td> <td>   -1.434</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP</th>                         <td>   10.1452</td> <td>    3.092</td> <td>    3.282</td> <td> 0.001</td> <td>    4.039</td> <td>   16.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DD2</th>                        <td>   -0.0525</td> <td>    0.348</td> <td>   -0.151</td> <td> 0.880</td> <td>   -0.740</td> <td>    0.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TD3</th>                        <td>   -0.1915</td> <td>    0.185</td> <td>   -1.033</td> <td> 0.303</td> <td>   -0.558</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>+/-</th>                        <td>    0.0664</td> <td>    0.577</td> <td>    0.115</td> <td> 0.908</td> <td>   -1.072</td> <td>    1.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Height</th>                     <td>    0.0484</td> <td>    0.410</td> <td>    0.118</td> <td> 0.906</td> <td>   -0.761</td> <td>    0.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Weight</th>                     <td>   -0.5483</td> <td>    0.323</td> <td>   -1.700</td> <td> 0.091</td> <td>   -1.185</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Draft_Number</th>               <td>    0.0964</td> <td>    0.192</td> <td>    0.502</td> <td> 0.617</td> <td>   -0.283</td> <td>    0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>%_Box_Outs_Off</th>             <td>   -0.3399</td> <td>    0.950</td> <td>   -0.358</td> <td> 0.721</td> <td>   -2.217</td> <td>    1.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>%_Box_Outs_Def</th>             <td>   -0.1243</td> <td>    0.986</td> <td>   -0.126</td> <td> 0.900</td> <td>   -2.072</td> <td>    1.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>%_Team_RebWhen_Box_Out</th>     <td>    0.1366</td> <td>    0.198</td> <td>    0.688</td> <td> 0.492</td> <td>   -0.255</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>%_Player_RebWhen_Box_Out</th>   <td>   -0.0544</td> <td>    0.297</td> <td>   -0.183</td> <td> 0.855</td> <td>   -0.640</td> <td>    0.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ContestedREB%</th>              <td>    0.0234</td> <td>    0.434</td> <td>    0.054</td> <td> 0.957</td> <td>   -0.833</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DeferredREB_Chances</th>        <td>   -0.3063</td> <td>    0.328</td> <td>   -0.934</td> <td> 0.352</td> <td>   -0.954</td> <td>    0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AdjustedREB_Chance%</th>        <td>    0.2509</td> <td>    0.291</td> <td>    0.861</td> <td> 0.390</td> <td>   -0.324</td> <td>    0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_REBDistance</th>            <td>    0.0288</td> <td>    0.596</td> <td>    0.048</td> <td> 0.961</td> <td>   -1.147</td> <td>    1.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PassesMade</th>                 <td>    0.0961</td> <td>    1.671</td> <td>    0.058</td> <td> 0.954</td> <td>   -3.204</td> <td>    3.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PassesReceived</th>             <td>   -2.4281</td> <td>    1.682</td> <td>   -1.444</td> <td> 0.151</td> <td>   -5.750</td> <td>    0.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SecondaryAST</th>               <td>    0.2621</td> <td>    0.454</td> <td>    0.577</td> <td> 0.565</td> <td>   -0.635</td> <td>    1.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASTAdj</th>                     <td>   -0.4524</td> <td>    2.663</td> <td>   -0.170</td> <td> 0.865</td> <td>   -5.712</td> <td>    4.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AST_ToPass%_Adj</th>            <td>   -0.6770</td> <td>    1.311</td> <td>   -0.517</td> <td> 0.606</td> <td>   -3.266</td> <td>    1.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ScreenAssists_PTS</th>          <td>    0.4580</td> <td>    0.379</td> <td>    1.209</td> <td> 0.228</td> <td>   -0.290</td> <td>    1.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Deflections</th>                <td>    0.8766</td> <td>    0.559</td> <td>    1.569</td> <td> 0.119</td> <td>   -0.227</td> <td>    1.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>%_Loose_BallsRecovered_OFF</th> <td>    0.3582</td> <td>    0.411</td> <td>    0.872</td> <td> 0.384</td> <td>   -0.453</td> <td>    1.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>%_Loose_BallsRecovered_DEF</th> <td>    0.3273</td> <td>    0.454</td> <td>    0.720</td> <td> 0.472</td> <td>   -0.570</td> <td>    1.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ChargesDrawn</th>               <td>   -0.2755</td> <td>    0.197</td> <td>   -1.402</td> <td> 0.163</td> <td>   -0.664</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Contested2PT_Shots</th>         <td>   -0.6034</td> <td>    0.521</td> <td>   -1.159</td> <td> 0.248</td> <td>   -1.632</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Contested3PT_Shots</th>         <td>   -0.0160</td> <td>    0.327</td> <td>   -0.049</td> <td> 0.961</td> <td>   -0.662</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FGM_und_5ft</th>                <td>    2.3475</td> <td>    0.696</td> <td>    3.375</td> <td> 0.001</td> <td>    0.974</td> <td>    3.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FG%_und_5ft</th>                <td>    0.3526</td> <td>    0.264</td> <td>    1.338</td> <td> 0.183</td> <td>   -0.168</td> <td>    0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FGM_5_9ft</th>                  <td>    0.7708</td> <td>    0.377</td> <td>    2.046</td> <td> 0.042</td> <td>    0.027</td> <td>    1.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FG%_5_9ft</th>                  <td>   -0.1299</td> <td>    0.257</td> <td>   -0.506</td> <td> 0.614</td> <td>   -0.637</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FGM_10_14ft</th>                <td>    0.6032</td> <td>    0.378</td> <td>    1.598</td> <td> 0.112</td> <td>   -0.142</td> <td>    1.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FG%_10_14ft</th>                <td>   -0.4042</td> <td>    0.234</td> <td>   -1.728</td> <td> 0.086</td> <td>   -0.866</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FGM_15_19ft</th>                <td>    0.9557</td> <td>    0.420</td> <td>    2.276</td> <td> 0.024</td> <td>    0.126</td> <td>    1.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FG%_15_19ft</th>                <td>    0.0783</td> <td>    0.229</td> <td>    0.343</td> <td> 0.732</td> <td>   -0.373</td> <td>    0.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FGM_und_5ft</th>            <td>    0.7364</td> <td>    1.314</td> <td>    0.560</td> <td> 0.576</td> <td>   -1.859</td> <td>    3.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FG%_und_5ft</th>            <td>   -0.0491</td> <td>    0.278</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.598</td> <td>    0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FGM_5_9ft</th>              <td>   -1.1568</td> <td>    0.531</td> <td>   -2.180</td> <td> 0.031</td> <td>   -2.205</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FG%_5_9ft</th>              <td>    1.0122</td> <td>    0.287</td> <td>    3.528</td> <td> 0.001</td> <td>    0.446</td> <td>    1.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FGM_10_14ft</th>            <td>    0.4366</td> <td>    0.628</td> <td>    0.695</td> <td> 0.488</td> <td>   -0.804</td> <td>    1.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FG%_10_14ft</th>            <td>    0.1945</td> <td>    0.257</td> <td>    0.758</td> <td> 0.450</td> <td>   -0.313</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FGM_15_19ft</th>            <td>   -1.0062</td> <td>    0.555</td> <td>   -1.812</td> <td> 0.072</td> <td>   -2.103</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FG%_15_19ft</th>            <td>    0.5581</td> <td>    0.318</td> <td>    1.756</td> <td> 0.081</td> <td>   -0.070</td> <td>    1.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FGM_20_24ft</th>            <td>   -1.5396</td> <td>    0.643</td> <td>   -2.395</td> <td> 0.018</td> <td>   -2.810</td> <td>   -0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FG%_20_24ft</th>            <td>    1.1793</td> <td>    0.286</td> <td>    4.123</td> <td> 0.000</td> <td>    0.614</td> <td>    1.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FGM_25_29ft</th>            <td>   -0.3674</td> <td>    0.761</td> <td>   -0.483</td> <td> 0.630</td> <td>   -1.871</td> <td>    1.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OPP_FG%_25_29ft</th>            <td>    0.7288</td> <td>    0.276</td> <td>    2.644</td> <td> 0.009</td> <td>    0.184</td> <td>    1.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DEFRTG</th>                     <td>   -2.1527</td> <td>    0.573</td> <td>   -3.755</td> <td> 0.000</td> <td>   -3.285</td> <td>   -1.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NETRTG</th>                     <td>   -1.2695</td> <td>    0.597</td> <td>   -2.127</td> <td> 0.035</td> <td>   -2.449</td> <td>   -0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AST%</th>                       <td>    1.3099</td> <td>    1.230</td> <td>    1.065</td> <td> 0.289</td> <td>   -1.120</td> <td>    3.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OREB%</th>                      <td>   -0.0499</td> <td>    0.483</td> <td>   -0.103</td> <td> 0.918</td> <td>   -1.003</td> <td>    0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DREB%</th>                      <td>    0.7156</td> <td>    0.737</td> <td>    0.971</td> <td> 0.333</td> <td>   -0.741</td> <td>    2.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eFG%</th>                       <td>   -0.3396</td> <td>    2.267</td> <td>   -0.150</td> <td> 0.881</td> <td>   -4.816</td> <td>    4.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TS%</th>                        <td>    1.2501</td> <td>    2.369</td> <td>    0.528</td> <td> 0.598</td> <td>   -3.428</td> <td>    5.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>USG%</th>                       <td>   -0.2798</td> <td>    1.178</td> <td>   -0.238</td> <td> 0.812</td> <td>   -2.606</td> <td>    2.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PACE</th>                       <td>   -0.1695</td> <td>    0.266</td> <td>   -0.637</td> <td> 0.525</td> <td>   -0.695</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_five_1</th>             <td>   -0.0961</td> <td>    0.328</td> <td>   -0.293</td> <td> 0.770</td> <td>   -0.744</td> <td>    0.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_five_2</th>             <td>   -0.1537</td> <td>    0.351</td> <td>   -0.438</td> <td> 0.662</td> <td>   -0.847</td> <td>    0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_five_3</th>             <td>   -0.2396</td> <td>    0.307</td> <td>   -0.779</td> <td> 0.437</td> <td>   -0.847</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_five_4</th>             <td>    0.3911</td> <td>    0.286</td> <td>    1.367</td> <td> 0.174</td> <td>   -0.174</td> <td>    0.956</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.013</td> <th>  Durbin-Watson:     </th> <td>   1.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  38.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.399</td> <th>  Prob(JB):          </th> <td>4.29e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.826</td> <th>  Cond. No.          </th> <td>    189.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               PIE_2018   R-squared:                       0.779\n",
       "Model:                            OLS   Adj. R-squared:                  0.673\n",
       "Method:                 Least Squares   F-statistic:                     7.375\n",
       "Date:                Wed, 30 Sep 2020   Prob (F-statistic):           5.76e-26\n",
       "Time:                        11:50:12   Log-Likelihood:                -461.48\n",
       "No. Observations:                 233   AIC:                             1075.\n",
       "Df Residuals:                     157   BIC:                             1337.\n",
       "Df Model:                          75                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "const                          9.4626      0.159     59.516      0.000       9.149       9.777\n",
       "PIE_2017                      -1.8306      1.061     -1.725      0.086      -3.927       0.265\n",
       "AGE                           -0.0978      0.186     -0.526      0.600      -0.465       0.269\n",
       "MIN_2017                      -0.2710      2.737     -0.099      0.921      -5.677       5.135\n",
       "GP                             3.5085      1.103      3.180      0.002       1.329       5.688\n",
       "W                             -1.9696      0.878     -2.242      0.026      -3.705      -0.235\n",
       "L                             -2.8366      0.807     -3.513      0.001      -4.432      -1.242\n",
       "PTS                            6.4535      4.155      1.553      0.122      -1.754      14.661\n",
       "FGM                           -8.4560      3.851     -2.196      0.030     -16.062      -0.850\n",
       "3P%                           -0.0528      0.234     -0.225      0.822      -0.516       0.410\n",
       "FTM                           -1.5486      0.971     -1.595      0.113      -3.467       0.369\n",
       "FT%                            0.3209      0.353      0.908      0.365      -0.377       1.019\n",
       "TOV                           -0.0298      0.614     -0.049      0.961      -1.243       1.183\n",
       "STL                           -1.9599      0.698     -2.809      0.006      -3.338      -0.582\n",
       "BLK                           -0.7936      0.437     -1.817      0.071      -1.656       0.069\n",
       "PF                            -0.6615      0.391     -1.692      0.093      -1.434       0.111\n",
       "FP                            10.1452      3.092      3.282      0.001       4.039      16.252\n",
       "DD2                           -0.0525      0.348     -0.151      0.880      -0.740       0.635\n",
       "TD3                           -0.1915      0.185     -1.033      0.303      -0.558       0.175\n",
       "+/-                            0.0664      0.577      0.115      0.908      -1.072       1.205\n",
       "Height                         0.0484      0.410      0.118      0.906      -0.761       0.858\n",
       "Weight                        -0.5483      0.323     -1.700      0.091      -1.185       0.089\n",
       "Draft_Number                   0.0964      0.192      0.502      0.617      -0.283       0.476\n",
       "%_Box_Outs_Off                -0.3399      0.950     -0.358      0.721      -2.217       1.537\n",
       "%_Box_Outs_Def                -0.1243      0.986     -0.126      0.900      -2.072       1.824\n",
       "%_Team_RebWhen_Box_Out         0.1366      0.198      0.688      0.492      -0.255       0.528\n",
       "%_Player_RebWhen_Box_Out      -0.0544      0.297     -0.183      0.855      -0.640       0.532\n",
       "ContestedREB%                  0.0234      0.434      0.054      0.957      -0.833       0.880\n",
       "DeferredREB_Chances           -0.3063      0.328     -0.934      0.352      -0.954       0.341\n",
       "AdjustedREB_Chance%            0.2509      0.291      0.861      0.390      -0.324       0.826\n",
       "AVG_REBDistance                0.0288      0.596      0.048      0.961      -1.147       1.205\n",
       "PassesMade                     0.0961      1.671      0.058      0.954      -3.204       3.396\n",
       "PassesReceived                -2.4281      1.682     -1.444      0.151      -5.750       0.893\n",
       "SecondaryAST                   0.2621      0.454      0.577      0.565      -0.635       1.160\n",
       "ASTAdj                        -0.4524      2.663     -0.170      0.865      -5.712       4.807\n",
       "AST_ToPass%_Adj               -0.6770      1.311     -0.517      0.606      -3.266       1.912\n",
       "ScreenAssists_PTS              0.4580      0.379      1.209      0.228      -0.290       1.206\n",
       "Deflections                    0.8766      0.559      1.569      0.119      -0.227       1.980\n",
       "%_Loose_BallsRecovered_OFF     0.3582      0.411      0.872      0.384      -0.453       1.169\n",
       "%_Loose_BallsRecovered_DEF     0.3273      0.454      0.720      0.472      -0.570       1.225\n",
       "ChargesDrawn                  -0.2755      0.197     -1.402      0.163      -0.664       0.113\n",
       "Contested2PT_Shots            -0.6034      0.521     -1.159      0.248      -1.632       0.425\n",
       "Contested3PT_Shots            -0.0160      0.327     -0.049      0.961      -0.662       0.630\n",
       "FGM_und_5ft                    2.3475      0.696      3.375      0.001       0.974       3.721\n",
       "FG%_und_5ft                    0.3526      0.264      1.338      0.183      -0.168       0.873\n",
       "FGM_5_9ft                      0.7708      0.377      2.046      0.042       0.027       1.515\n",
       "FG%_5_9ft                     -0.1299      0.257     -0.506      0.614      -0.637       0.377\n",
       "FGM_10_14ft                    0.6032      0.378      1.598      0.112      -0.142       1.349\n",
       "FG%_10_14ft                   -0.4042      0.234     -1.728      0.086      -0.866       0.058\n",
       "FGM_15_19ft                    0.9557      0.420      2.276      0.024       0.126       1.785\n",
       "FG%_15_19ft                    0.0783      0.229      0.343      0.732      -0.373       0.530\n",
       "OPP_FGM_und_5ft                0.7364      1.314      0.560      0.576      -1.859       3.332\n",
       "OPP_FG%_und_5ft               -0.0491      0.278     -0.177      0.860      -0.598       0.500\n",
       "OPP_FGM_5_9ft                 -1.1568      0.531     -2.180      0.031      -2.205      -0.109\n",
       "OPP_FG%_5_9ft                  1.0122      0.287      3.528      0.001       0.446       1.579\n",
       "OPP_FGM_10_14ft                0.4366      0.628      0.695      0.488      -0.804       1.677\n",
       "OPP_FG%_10_14ft                0.1945      0.257      0.758      0.450      -0.313       0.702\n",
       "OPP_FGM_15_19ft               -1.0062      0.555     -1.812      0.072      -2.103       0.091\n",
       "OPP_FG%_15_19ft                0.5581      0.318      1.756      0.081      -0.070       1.186\n",
       "OPP_FGM_20_24ft               -1.5396      0.643     -2.395      0.018      -2.810      -0.270\n",
       "OPP_FG%_20_24ft                1.1793      0.286      4.123      0.000       0.614       1.744\n",
       "OPP_FGM_25_29ft               -0.3674      0.761     -0.483      0.630      -1.871       1.136\n",
       "OPP_FG%_25_29ft                0.7288      0.276      2.644      0.009       0.184       1.273\n",
       "DEFRTG                        -2.1527      0.573     -3.755      0.000      -3.285      -1.020\n",
       "NETRTG                        -1.2695      0.597     -2.127      0.035      -2.449      -0.090\n",
       "AST%                           1.3099      1.230      1.065      0.289      -1.120       3.739\n",
       "OREB%                         -0.0499      0.483     -0.103      0.918      -1.003       0.903\n",
       "DREB%                          0.7156      0.737      0.971      0.333      -0.741       2.172\n",
       "eFG%                          -0.3396      2.267     -0.150      0.881      -4.816       4.137\n",
       "TS%                            1.2501      2.369      0.528      0.598      -3.428       5.929\n",
       "USG%                          -0.2798      1.178     -0.238      0.812      -2.606       2.046\n",
       "PACE                          -0.1695      0.266     -0.637      0.525      -0.695       0.356\n",
       "cluster_five_1                -0.0961      0.328     -0.293      0.770      -0.744       0.551\n",
       "cluster_five_2                -0.1537      0.351     -0.438      0.662      -0.847       0.539\n",
       "cluster_five_3                -0.2396      0.307     -0.779      0.437      -0.847       0.368\n",
       "cluster_five_4                 0.3911      0.286      1.367      0.174      -0.174       0.956\n",
       "==============================================================================\n",
       "Omnibus:                       19.013   Durbin-Watson:                   1.866\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.532\n",
       "Skew:                           0.399   Prob(JB):                     4.29e-09\n",
       "Kurtosis:                       4.826   Cond. No.                         189.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the OLS model \n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>10.145189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>9.462576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGM</th>\n",
       "      <td>8.455962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS</th>\n",
       "      <td>6.453503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP</th>\n",
       "      <td>3.508486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>2.836634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassesReceived</th>\n",
       "      <td>2.428128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGM_und_5ft</th>\n",
       "      <td>2.347453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEFRTG</th>\n",
       "      <td>2.152735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>1.969614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Coefficient\n",
       "FP                10.145189\n",
       "const              9.462576\n",
       "FGM                8.455962\n",
       "PTS                6.453503\n",
       "GP                 3.508486\n",
       "L                  2.836634\n",
       "PassesReceived     2.428128\n",
       "FGM_und_5ft        2.347453\n",
       "DEFRTG             2.152735\n",
       "W                  1.969614"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete this, inspect coeefficients at some later point?\n",
    "\n",
    "# Inspecting the most important coefficients of the model.\n",
    "pd.DataFrame(abs(ols.params), X.columns, columns=['Coefficient']).sort_values(by='Coefficient', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.metrics import r2_score   \\nr2_score(y_test, y_pred)   \\nprint(1-(1-r2_score(y_test, y_pred))*((len(X_test)-1)/(len(X_test)-len(X_test[0])-1)))\\n'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE:\n",
    "\n",
    "# write adjusted r2 function\n",
    "\n",
    "#something like this:\n",
    "\"\"\"\n",
    "from sklearn.metrics import r2_score   \n",
    "r2_score(y_test, y_pred)   \n",
    "print(1-(1-r2_score(y_test, y_pred))*((len(X_test)-1)/(len(X_test)-len(X_test[0])-1)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.0242414166296223\n",
      "Explained Variance Score:  0.10297286106849535\n"
     ]
    }
   ],
   "source": [
    "# making predictions with OLS\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = ols.predict(X_test)\n",
    "\n",
    "m1_scores = mean_squared_error(y_test, y_pred) ** 0.5, r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"RMSE: \", m1_scores[0])\n",
    "print(\"Explained Variance Score: \", m1_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Resetting the Training Data (a constant was added from the Statsmodels iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Player','PIE_2018'], axis=1)\n",
    "y = df.PIE_2018\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Model (Heuristically Tuned with GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha paramater for Lasso Regression: alpha = 0.15 \n",
      "\n",
      "Below is a dataframe of the best parameters found through the grids search sorted by lowest mean squared error.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.004395</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'alpha': 0.15}</td>\n",
       "      <td>-5.707349</td>\n",
       "      <td>-9.336262</td>\n",
       "      <td>-11.367728</td>\n",
       "      <td>-4.503744</td>\n",
       "      <td>-3.213665</td>\n",
       "      <td>-6.825750</td>\n",
       "      <td>3.053585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.175</td>\n",
       "      <td>{'alpha': 0.175}</td>\n",
       "      <td>-5.670510</td>\n",
       "      <td>-9.541660</td>\n",
       "      <td>-11.357481</td>\n",
       "      <td>-4.434357</td>\n",
       "      <td>-3.227428</td>\n",
       "      <td>-6.846287</td>\n",
       "      <td>3.095542</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>-5.641979</td>\n",
       "      <td>-9.767123</td>\n",
       "      <td>-11.324242</td>\n",
       "      <td>-4.325156</td>\n",
       "      <td>-3.241454</td>\n",
       "      <td>-6.859991</td>\n",
       "      <td>3.142728</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.225</td>\n",
       "      <td>{'alpha': 0.225}</td>\n",
       "      <td>-5.606115</td>\n",
       "      <td>-9.951020</td>\n",
       "      <td>-11.295081</td>\n",
       "      <td>-4.286814</td>\n",
       "      <td>-3.240089</td>\n",
       "      <td>-6.875824</td>\n",
       "      <td>3.178691</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 0.25}</td>\n",
       "      <td>-5.627038</td>\n",
       "      <td>-10.030583</td>\n",
       "      <td>-11.285978</td>\n",
       "      <td>-4.322620</td>\n",
       "      <td>-3.243705</td>\n",
       "      <td>-6.901985</td>\n",
       "      <td>3.183367</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "20       0.004395      0.001060         0.001367        0.000245        0.15   \n",
       "19       0.004935      0.003632         0.001738        0.000738       0.175   \n",
       "18       0.003419      0.000045         0.001435        0.000101         0.2   \n",
       "17       0.002516      0.000643         0.001006        0.000229       0.225   \n",
       "16       0.001981      0.000038         0.000820        0.000004        0.25   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "20   {'alpha': 0.15}          -5.707349          -9.336262         -11.367728   \n",
       "19  {'alpha': 0.175}          -5.670510          -9.541660         -11.357481   \n",
       "18    {'alpha': 0.2}          -5.641979          -9.767123         -11.324242   \n",
       "17  {'alpha': 0.225}          -5.606115          -9.951020         -11.295081   \n",
       "16   {'alpha': 0.25}          -5.627038         -10.030583         -11.285978   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "20          -4.503744          -3.213665        -6.825750        3.053585   \n",
       "19          -4.434357          -3.227428        -6.846287        3.095542   \n",
       "18          -4.325156          -3.241454        -6.859991        3.142728   \n",
       "17          -4.286814          -3.240089        -6.875824        3.178691   \n",
       "16          -4.322620          -3.243705        -6.901985        3.183367   \n",
       "\n",
       "    rank_test_score  \n",
       "20                1  \n",
       "19                2  \n",
       "18                3  \n",
       "17                4  \n",
       "16                5  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso with Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'alpha': [25,10,4,3,2.5,2,1.5,1.0,0.8,0.5,0.4,0.375,0.35,0.325,0.3,0.275,0.25,0.225, 0.2,0.175, 0.15,0.1,0.05,0.02,0.01,0.001,0.0001]}\n",
    "\n",
    "lasso = Lasso(max_iter=50000)\n",
    "clf = GridSearchCV(lasso, params, cv=5,verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# pauing for Grid Search to finish. \n",
    "time.sleep(5)\n",
    "\n",
    "# cell break\n",
    "best_lasso_alpha = clf.best_params_['alpha']\n",
    "print(\"Best alpha paramater for Lasso Regression: alpha =\", best_lasso_alpha, \"\\n\")\n",
    "\n",
    "\n",
    "print(\"Below is a dataframe of the best parameters found through the grids search sorted by lowest mean squared error.\")\n",
    "pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_score').head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.3599055355709226\n",
      "Explained Variance Score:  0.4537871574264597\n"
     ]
    }
   ],
   "source": [
    "# Scoring Lasso Model\n",
    "\n",
    "lasso=Lasso(alpha=best_lasso_alpha, max_iter=50000,random_state=33)\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_preds=lasso.predict(X_test)\n",
    "\n",
    "m2_scores = mean_squared_error(y_test, lasso_preds) ** 0.5, r2_score(y_test, lasso_preds)\n",
    "\n",
    "print(\"RMSE: \", m2_scores[0])\n",
    "print(\"Explained Variance Score: \", m2_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Model (Heuristically Tuned with GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha paramater for Ridge Regressions: alpha = 0.8 \n",
      "\n",
      "Best parameters found through the Grid Search sorted by lowest mean squared error.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>-5.711152</td>\n",
       "      <td>-15.145416</td>\n",
       "      <td>-4.537361</td>\n",
       "      <td>-2.892242</td>\n",
       "      <td>-7.071543</td>\n",
       "      <td>4.767775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>-5.799458</td>\n",
       "      <td>-14.953070</td>\n",
       "      <td>-4.641104</td>\n",
       "      <td>-2.892691</td>\n",
       "      <td>-7.071581</td>\n",
       "      <td>4.666543</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>-5.702383</td>\n",
       "      <td>-15.269916</td>\n",
       "      <td>-4.537033</td>\n",
       "      <td>-2.940011</td>\n",
       "      <td>-7.112336</td>\n",
       "      <td>4.810784</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>-5.969324</td>\n",
       "      <td>-14.855318</td>\n",
       "      <td>-4.886400</td>\n",
       "      <td>-3.054021</td>\n",
       "      <td>-7.191266</td>\n",
       "      <td>4.545878</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>1.5</td>\n",
       "      <td>{'alpha': 1.5}</td>\n",
       "      <td>-5.761994</td>\n",
       "      <td>-15.545572</td>\n",
       "      <td>-4.624844</td>\n",
       "      <td>-3.101548</td>\n",
       "      <td>-7.258489</td>\n",
       "      <td>4.876769</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "12       0.003215      0.000135         0.001416        0.000106         0.8   \n",
       "13       0.002778      0.000621         0.001086        0.000172         0.5   \n",
       "11       0.003494      0.000137         0.001513        0.000149           1   \n",
       "14       0.002118      0.000131         0.000994        0.000242         0.3   \n",
       "10       0.002992      0.001006         0.002225        0.001968         1.5   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "12  {'alpha': 0.8}          -5.711152         -15.145416          -4.537361   \n",
       "13  {'alpha': 0.5}          -5.799458         -14.953070          -4.641104   \n",
       "11  {'alpha': 1.0}          -5.702383         -15.269916          -4.537033   \n",
       "14  {'alpha': 0.3}          -5.969324         -14.855318          -4.886400   \n",
       "10  {'alpha': 1.5}          -5.761994         -15.545572          -4.624844   \n",
       "\n",
       "    split3_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "12          -2.892242        -7.071543        4.767775                1  \n",
       "13          -2.892691        -7.071581        4.666543                2  \n",
       "11          -2.940011        -7.112336        4.810784                3  \n",
       "14          -3.054021        -7.191266        4.545878                4  \n",
       "10          -3.101548        -7.258489        4.876769                5  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note I manually tested different parameters for cross-validation(cv) and 4 had the lowest mean_test_scores.\n",
    "\n",
    "params={'alpha': [1000,500,100,50,25,10,4,3,2.5,2,1.5,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]}\n",
    "ridge = Ridge(normalize=True,random_state=33)\n",
    "clf = GridSearchCV(ridge, params, cv=4,verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# pauing for Grid Search to finish. \n",
    "time.sleep(5)\n",
    "\n",
    "best_ridge_alpha = clf.best_params_['alpha']\n",
    "print(\"Best alpha paramater for Ridge Regressions: alpha =\", best_ridge_alpha,\"\\n\")\n",
    "\n",
    "print(\"Best parameters found through the Grid Search sorted by lowest mean squared error.\")\n",
    "pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.361449343355488\n",
      "Explained Variance Score:  0.4530722784243941\n"
     ]
    }
   ],
   "source": [
    "# Scoring Ridge Model\n",
    "\n",
    "ridge = Ridge(alpha=best_ridge_alpha, normalize=True,random_state=33)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_preds = ridge.predict(X_test)\n",
    "\n",
    "m3_scores = mean_squared_error(y_test, ridge_preds) ** 0.5, r2_score(y_test, ridge_preds)\n",
    "\n",
    "print(\"RMSE: \", m3_scores[0])\n",
    "print(\"Explained Variance Score: \", m3_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net (Heuristically Tuned with GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramaters for Elastic Net: {'alpha': 0.4001, 'l1_ratio': 0.050100000000000006} \n",
      "\n",
      "Best parameters found through the Grid Search sorted by lowest mean squared error.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.4001</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>{'alpha': 0.4001, 'l1_ratio': 0.05010000000000...</td>\n",
       "      <td>-7.598168</td>\n",
       "      <td>-7.507686</td>\n",
       "      <td>-3.799399</td>\n",
       "      <td>-6.301751</td>\n",
       "      <td>1.769816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.3501</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>{'alpha': 0.3501, 'l1_ratio': 0.10010000000000...</td>\n",
       "      <td>-7.567932</td>\n",
       "      <td>-7.508864</td>\n",
       "      <td>-3.836667</td>\n",
       "      <td>-6.304487</td>\n",
       "      <td>1.745180</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "161       0.003087      0.000167         0.000870        0.000032      0.4001   \n",
       "142       0.003080      0.000034         0.000948        0.000028      0.3501   \n",
       "\n",
       "    param_l1_ratio                                             params  \\\n",
       "161         0.0501  {'alpha': 0.4001, 'l1_ratio': 0.05010000000000...   \n",
       "142         0.1001  {'alpha': 0.3501, 'l1_ratio': 0.10010000000000...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "161          -7.598168          -7.507686          -3.799399        -6.301751   \n",
       "142          -7.567932          -7.508864          -3.836667        -6.304487   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "161        1.769816                1  \n",
       "142        1.745180                2  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elastic Net with Grid Search\n",
    "\n",
    "parametersGrid = {\"alpha\": np.arange(0.0001, 1.0, 0.05),\n",
    "                  \"l1_ratio\": np.arange(0.0001, 1.0, 0.05)}\n",
    "\n",
    "eNet = ElasticNet(max_iter=100000, tol=0.0001, random_state=33)\n",
    "grid = GridSearchCV(eNet, parametersGrid, scoring='neg_mean_squared_error', cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# pauing for Grid Search to finish. \n",
    "time.sleep(5)\n",
    "\n",
    "best_elastic_params = grid.best_params_\n",
    "print(\"Best paramaters for Elastic Net:\", best_elastic_params, \"\\n\")\n",
    "\n",
    "print(\"Best parameters found through the Grid Search sorted by lowest mean squared error.\")\n",
    "pd.DataFrame(grid.cv_results_).sort_values(by='rank_test_score').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.394136543794397\n",
      "Explained Variance Score:  0.4378263307533352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "elastic = ElasticNet(alpha = best_elastic_params['alpha'], l1_ratio=best_elastic_params['l1_ratio'],random_state=33)\n",
    "elastic.fit(X_train, y_train)\n",
    "e_preds = elastic.predict(X_test)\n",
    "\n",
    "m4_scores = mean_squared_error(y_test, e_preds) ** 0.5, r2_score(y_test, e_preds)\n",
    "\n",
    "print(\"RMSE: \", m4_scores[0])\n",
    "print(\"Explained Variance Score: \", m4_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PIE_2017</th>\n",
       "      <td>0.545017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DREB%</th>\n",
       "      <td>0.420998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USG%</th>\n",
       "      <td>0.347099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG%_und_5ft</th>\n",
       "      <td>0.340419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>0.335802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG%_10_14ft</th>\n",
       "      <td>0.307698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGM_5_9ft</th>\n",
       "      <td>0.296538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_five_4</th>\n",
       "      <td>0.284746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGM_und_5ft</th>\n",
       "      <td>0.282608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPP_FG%_und_5ft</th>\n",
       "      <td>0.282211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdjustedREB_Chance%</th>\n",
       "      <td>0.279050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PACE</th>\n",
       "      <td>0.275933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DD2</th>\n",
       "      <td>0.275900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST%</th>\n",
       "      <td>0.249369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGM_15_19ft</th>\n",
       "      <td>0.247264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPP_FG%_20_24ft</th>\n",
       "      <td>0.235904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPP_FG%_5_9ft</th>\n",
       "      <td>0.221232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>0.209722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenAssists_PTS</th>\n",
       "      <td>0.195063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+/-</th>\n",
       "      <td>0.194220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coefficient\n",
       "PIE_2017                0.545017\n",
       "DREB%                   0.420998\n",
       "USG%                    0.347099\n",
       "FG%_und_5ft             0.340419\n",
       "L                       0.335802\n",
       "FG%_10_14ft             0.307698\n",
       "FGM_5_9ft               0.296538\n",
       "cluster_five_4          0.284746\n",
       "FGM_und_5ft             0.282608\n",
       "OPP_FG%_und_5ft         0.282211\n",
       "AdjustedREB_Chance%     0.279050\n",
       "PACE                    0.275933\n",
       "DD2                     0.275900\n",
       "AST%                    0.249369\n",
       "FGM_15_19ft             0.247264\n",
       "OPP_FG%_20_24ft         0.235904\n",
       "OPP_FG%_5_9ft           0.221232\n",
       "FP                      0.209722\n",
       "ScreenAssists_PTS       0.195063\n",
       "+/-                     0.194220"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after model selection before hyper tuning\n",
    "\n",
    "# Inspecting the most important coefficients of the model.\n",
    "\n",
    "pd.DataFrame(abs(elastic.coef_), X.columns, columns=['Coefficient']).sort_values(by='Coefficient', ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.251730834269496\n",
      "Explained Variance Score:  0.5027147029141321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=33)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "m5_scores = mean_squared_error(y_test, rf_preds) ** 0.5, r2_score(y_test, rf_preds)\n",
    "\n",
    "print(\"RMSE: \", m5_scores[0])\n",
    "print(\"Explained Variance Score: \", m5_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.2005204314978117\n",
      "Explained Variance Score:  0.5250766969207229\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgbr = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = 10, seed = 33) \n",
    "xgbr.fit(X_train, y_train)\n",
    "xgb_preds = xgbr.predict(X_test) \n",
    "\n",
    "m6_scores = mean_squared_error(y_test, xgb_preds) ** 0.5, r2_score(y_test, xgb_preds)\n",
    "\n",
    "print(\"RMSE: \", m6_scores[0])\n",
    "print(\"Explained Variance Score: \", m6_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing All Models and Identifying Best Model to Select for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Explained Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>2.20</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Forest</th>\n",
       "      <td>2.25</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>2.36</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.36</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elastic_Net</th>\n",
       "      <td>2.39</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmOLS</th>\n",
       "      <td>3.02</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RMSE  Explained Variance\n",
       "XGBoost        2.20                0.53\n",
       "Random_Forest  2.25                0.50\n",
       "Lasso          2.36                0.45\n",
       "Ridge          2.36                0.45\n",
       "Elastic_Net    2.39                0.44\n",
       "SmOLS          3.02                0.10"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(data= [m1_scores,m2_scores,m3_scores,m4_scores,m5_scores,m6_scores],\n",
    "             columns=['RMSE','Explained Variance'],\n",
    "             index=['SmOLS','Lasso','Ridge','Elastic_Net', 'Random_Forest', 'XGBoost'])\\\n",
    "            .sort_values(by='RMSE').round(2)\n",
    "\n",
    "scores_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis: Given that Random Forest and XGBoost do not give interpretable results for regression models, I will use Elastic Net moving forward as previous iterations of modeling proved that Elastic Net provided better results with further hypertuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Elastic Net with RandomizedGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "elastic = ElasticNet(random_state=33, max_iter=10000)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'l1_ratio': stats.uniform(0.0001, 1),\n",
    "              'alpha': stats.uniform(0.0001, 1)}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(elastic, param_distributions=param_dist,\n",
    "                                   n_iter = n_iter_search)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramaters for Elastic Net: {'alpha': 0.41403265652050947, 'l1_ratio': 0.13401022448116107}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.414033</td>\n",
       "      <td>0.13401</td>\n",
       "      <td>{'alpha': 0.41403265652050947, 'l1_ratio': 0.1...</td>\n",
       "      <td>0.520359</td>\n",
       "      <td>0.437243</td>\n",
       "      <td>0.443869</td>\n",
       "      <td>0.672654</td>\n",
       "      <td>0.646239</td>\n",
       "      <td>0.544073</td>\n",
       "      <td>0.098982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.342829</td>\n",
       "      <td>0.631277</td>\n",
       "      <td>{'alpha': 0.34282897602930795, 'l1_ratio': 0.6...</td>\n",
       "      <td>0.512204</td>\n",
       "      <td>0.407474</td>\n",
       "      <td>0.411414</td>\n",
       "      <td>0.665506</td>\n",
       "      <td>0.620195</td>\n",
       "      <td>0.523359</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "11       0.002962      0.000126         0.001118        0.000106    0.414033   \n",
       "17       0.002404      0.000166         0.001063        0.000017    0.342829   \n",
       "\n",
       "   param_l1_ratio                                             params  \\\n",
       "11        0.13401  {'alpha': 0.41403265652050947, 'l1_ratio': 0.1...   \n",
       "17       0.631277  {'alpha': 0.34282897602930795, 'l1_ratio': 0.6...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "11           0.520359           0.437243           0.443869   \n",
       "17           0.512204           0.407474           0.411414   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "11           0.672654           0.646239         0.544073        0.098982   \n",
       "17           0.665506           0.620195         0.523359        0.105516   \n",
       "\n",
       "    rank_test_score  \n",
       "11                1  \n",
       "17                2  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_elastic_random_params = random_search.best_params_\n",
    "print(\"Best paramaters for Elastic Net:\", best_elastic_random_params)\n",
    "\n",
    "pd.DataFrame(random_search.cv_results_).sort_values(by='rank_test_score').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Elastic Net with Random Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.3586505490732685\n",
      "Explained Variance Score:  0.454367949718235\n"
     ]
    }
   ],
   "source": [
    "random_elastic = ElasticNet(alpha = best_elastic_random_params['alpha'], l1_ratio=best_elastic_random_params['l1_ratio'],random_state=33)\n",
    "random_elastic.fit(X_train, y_train)\n",
    "e_preds = random_elastic.predict(X_test)\n",
    "\n",
    "random_elastic_grid_scores = mean_squared_error(y_test, e_preds) ** 0.5, r2_score(y_test, e_preds)\n",
    "\n",
    "print(\"RMSE: \", random_elastic_grid_scores[0])\n",
    "print(\"Explained Variance Score: \", random_elastic_grid_scores[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Defining scoring function to pass into Bayesian Optimizer\n",
    "\n",
    "def elastic_func(**params):\n",
    "        \n",
    "    random_elastic = ElasticNet(alpha = params['alpha'], l1_ratio = params['l1_ratio'], random_state=33)\n",
    "    \n",
    "    random_elastic.fit(X_train, y_train)\n",
    "    e_preds = random_elastic.predict(X_test)\n",
    "\n",
    "    random_elastic_grid_score = mean_squared_error(y_test, e_preds) \n",
    "    print(\"RMSE: \", random_elastic_grid_scores[0])\n",
    "    \n",
    "    return random_elastic_grid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   | l1_ratio  |\n",
      "-------------------------------------------------\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 5.518   \u001b[0m | \u001b[0m 0.2486  \u001b[0m | \u001b[0m 0.45    \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 5.413   \u001b[0m | \u001b[0m 0.411   \u001b[0m | \u001b[0m 0.2604  \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 5.322   \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 0.1851  \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 6.826   \u001b[0m | \u001b[95m 0.01976 \u001b[0m | \u001b[95m 0.9533  \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 5.246   \u001b[0m | \u001b[0m 0.6805  \u001b[0m | \u001b[0m 0.4866  \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 5.205   \u001b[0m | \u001b[0m 0.2515  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 6.802   \u001b[0m | \u001b[0m 0.04892 \u001b[0m | \u001b[0m 0.207   \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 5.322   \u001b[0m | \u001b[0m 0.5231  \u001b[0m | \u001b[0m 0.2522  \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 8.789   \u001b[0m | \u001b[95m 0.0001  \u001b[0m | \u001b[95m 0.0001  \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 6.685   \u001b[0m | \u001b[0m 0.07839 \u001b[0m | \u001b[0m 0.000239\u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mateo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 362.1679085015032, tolerance: 0.3240685150214592\n",
      "  positive)\n",
      "/Users/Mateo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 361.5273256085928, tolerance: 0.3240685150214592\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.3586505490732685\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 8.792   \u001b[0m | \u001b[95m 0.0001  \u001b[0m | \u001b[95m 0.03032 \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 8.798   \u001b[0m | \u001b[95m 0.0001  \u001b[0m | \u001b[95m 0.08093 \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 5.655   \u001b[0m | \u001b[0m 0.1521  \u001b[0m | \u001b[0m 0.7644  \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 7.678   \u001b[0m | \u001b[0m 0.001624\u001b[0m | \u001b[0m 0.07883 \u001b[0m |\n",
      "RMSE:  2.3586505490732685\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 5.193   \u001b[0m | \u001b[0m 0.3313  \u001b[0m | \u001b[0m 0.719   \u001b[0m |\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mateo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 360.46497983186225, tolerance: 0.3240685150214592\n",
      "  positive)\n",
      "/Users/Mateo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 323.19283991253303, tolerance: 0.3240685150214592\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "params = {'l1_ratio': (0.0001, 1),\n",
    "              'alpha': (0.0001, 1)}\n",
    "\n",
    "bo = BayesianOptimization(elastic_func, params, random_state=33)\n",
    "bo.maximize(init_points=5, n_iter=10, acq='ucb', kappa=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramaters for Elastic Net with Bayesian Optimization: \n",
      " {'alpha': 0.6804827596505661, 'l1_ratio': 0.4866394677378728}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.246098</td>\n",
       "      <td>{'alpha': 0.6804827596505661, 'l1_ratio': 0.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.322234</td>\n",
       "      <td>{'alpha': 0.8704086487781147, 'l1_ratio': 0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.412941</td>\n",
       "      <td>{'alpha': 0.4109997089162411, 'l1_ratio': 0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.518351</td>\n",
       "      <td>{'alpha': 0.24858527642498615, 'l1_ratio': 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.825901</td>\n",
       "      <td>{'alpha': 0.019759459287501006, 'l1_ratio': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                             params\n",
       "4  5.246098  {'alpha': 0.6804827596505661, 'l1_ratio': 0.48...\n",
       "2  5.322234  {'alpha': 0.8704086487781147, 'l1_ratio': 0.18...\n",
       "1  5.412941  {'alpha': 0.4109997089162411, 'l1_ratio': 0.26...\n",
       "0  5.518351  {'alpha': 0.24858527642498615, 'l1_ratio': 0.4...\n",
       "3  6.825901  {'alpha': 0.019759459287501006, 'l1_ratio': 0...."
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_bayes_df = pd.DataFrame(bo.res).head().sort_values(by='target')\n",
    "\n",
    "\n",
    "best_elastic_bayes_params = elastic_bayes_df.iloc[0][1]\n",
    "print(\"Best paramaters for Elastic Net with Bayesian Optimization: \\n\",  best_elastic_bayes_params)\n",
    "\n",
    "elastic_bayes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.2904362153670657\n",
      "Explained Variance Score:  0.4854719295688946\n"
     ]
    }
   ],
   "source": [
    "bayes = ElasticNet(alpha = best_elastic_bayes_params['alpha'], l1_ratio=best_elastic_bayes_params['l1_ratio'], random_state=33)\n",
    "bayes.fit(X_train, y_train)\n",
    "e_preds = bayes.predict(X_test)\n",
    "\n",
    "bayes_elastic_scores = mean_squared_error(y_test, e_preds) ** 0.5, r2_score(y_test, e_preds)\n",
    "\n",
    "print(\"RMSE: \", bayes_elastic_scores[0])\n",
    "print(\"Explained Variance Score: \", bayes_elastic_scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Below is a graph of the model's predictions vs. their true values. We can see a few significant outliers\n",
    "\n",
    "##### (note: how to I reconnect my model predictions back to the orginal datafame?( Yes, index remains) Analyze player names after all models run.\n",
    "\n",
    "\n",
    "\n",
    "# Plot the predictions\n",
    "# Build a scatterplot\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.scatter(y_test,y_pred - y_test)\n",
    "# Add a line for perfect correlation\n",
    "plt.plot([0,25],[0,0],c='r')\n",
    "# Label it nicely\n",
    "plt.xlabel('True Values of Test Data(PIE_2018)')\n",
    "plt.ylabel('Error of Predicted Values')\n",
    "plt.title('Distance from True Value and Predicted Value of PIE_2018 (Errors)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important model coefficients:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PIE_2017</th>\n",
       "      <td>0.802379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USG%</th>\n",
       "      <td>0.428888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DREB%</th>\n",
       "      <td>0.423019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGM_5_9ft</th>\n",
       "      <td>0.328868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DD2</th>\n",
       "      <td>0.237369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGM_und_5ft</th>\n",
       "      <td>0.214907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>0.175680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG%_und_5ft</th>\n",
       "      <td>0.160188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPP_FG%_und_5ft</th>\n",
       "      <td>0.115885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_five_4</th>\n",
       "      <td>0.112460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coefficient\n",
       "PIE_2017            0.802379\n",
       "USG%                0.428888\n",
       "DREB%               0.423019\n",
       "FGM_5_9ft           0.328868\n",
       "DD2                 0.237369\n",
       "FGM_und_5ft         0.214907\n",
       "L                   0.175680\n",
       "FG%_und_5ft         0.160188\n",
       "OPP_FG%_und_5ft     0.115885\n",
       "cluster_five_4      0.112460"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most important model coefficients:')\n",
    "\n",
    "pd.DataFrame(abs(bayes.coef_), X.columns, columns=['Coefficient'])\\\n",
    "             .sort_values(by='Coefficient', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis/Review/Conclusion\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider evaluating models against training data to evaluate comparison between training and testing prediction results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider Evaluating Model by comparing difference between predictions on training data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WAIT WHY IS IT BETTER SCORE ON TEST RATHER THAN TRAINING?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.515710502213607\n",
      "Explained Variance Score:  0.544969604957396\n"
     ]
    }
   ],
   "source": [
    "# Predictions on Training data\n",
    "\n",
    "training_preds = bayes.predict(X_train)\n",
    "\n",
    "training_scores = mean_squared_error(y_train, training_preds) ** 0.5, r2_score(y_train, training_preds)\n",
    "\n",
    "print(\"RMSE: \", training_scores[0])\n",
    "print(\"Explained Variance Score: \", training_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hap Hazardly analzying results (previous more below, much got deleted)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Worst Player Predictions (where did the model go wrong?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>PIE_2017</th>\n",
       "      <th>PIE_2018</th>\n",
       "      <th>predictions</th>\n",
       "      <th>diffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Wade Baldwin IV</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.722691</td>\n",
       "      <td>7.622691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>8.7</td>\n",
       "      <td>16.2</td>\n",
       "      <td>9.044617</td>\n",
       "      <td>7.155383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>18.6</td>\n",
       "      <td>21.8</td>\n",
       "      <td>15.098883</td>\n",
       "      <td>6.701117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.218266</td>\n",
       "      <td>5.718266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Ekpe Udoh</td>\n",
       "      <td>7.2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.274054</td>\n",
       "      <td>5.225946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Joakim Noah</td>\n",
       "      <td>11.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>9.176939</td>\n",
       "      <td>5.023061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.825666</td>\n",
       "      <td>4.925666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Mike Conley</td>\n",
       "      <td>10.9</td>\n",
       "      <td>15.1</td>\n",
       "      <td>10.378673</td>\n",
       "      <td>4.721327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Ryan Anderson</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.247519</td>\n",
       "      <td>4.647519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.378672</td>\n",
       "      <td>4.621328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Derrick Rose</td>\n",
       "      <td>6.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8.296664</td>\n",
       "      <td>4.503336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>15.256334</td>\n",
       "      <td>4.443666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>TJ Leaf</td>\n",
       "      <td>6.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.658570</td>\n",
       "      <td>4.441430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Walt Lemon Jr.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6.663613</td>\n",
       "      <td>4.236387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Quincy Pondexter</td>\n",
       "      <td>1.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.126303</td>\n",
       "      <td>3.873697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Skal Labissiere</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>10.065822</td>\n",
       "      <td>3.665822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.190646</td>\n",
       "      <td>3.490646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>16.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>14.215646</td>\n",
       "      <td>3.484354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Wilson Chandler</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.981502</td>\n",
       "      <td>3.381502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Boban Marjanovic</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13.047286</td>\n",
       "      <td>3.352714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Player  PIE_2017  PIE_2018  predictions     diffs\n",
       "101        Wade Baldwin IV       9.4       2.1     9.722691  7.622691\n",
       "21          JaKarr Sampson       8.7      16.2     9.044617  7.155383\n",
       "111  Giannis Antetokounmpo      18.6      21.8    15.098883  6.701117\n",
       "95         Andrew Harrison       8.3       2.5     8.218266  5.718266\n",
       "142              Ekpe Udoh       7.2      12.5     7.274054  5.225946\n",
       "5              Joakim Noah      11.4      14.2     9.176939  5.023061\n",
       "97           Isaiah Thomas       7.7       3.9     8.825666  4.925666\n",
       "147            Mike Conley      10.9      15.1    10.378673  4.721327\n",
       "62           Ryan Anderson       7.7       3.6     8.247519  4.647519\n",
       "152            Rudy Gobert      14.7      17.0    12.378672  4.621328\n",
       "42            Derrick Rose       6.8      12.8     8.296664  4.503336\n",
       "99           Anthony Davis      18.8      19.7    15.256334  4.443666\n",
       "102                TJ Leaf       6.1      11.1     6.658570  4.441430\n",
       "106         Walt Lemon Jr.       3.0      10.9     6.663613  4.236387\n",
       "135       Quincy Pondexter       1.9       9.0     5.126303  3.873697\n",
       "27         Skal Labissiere       8.4       6.4    10.065822  3.665822\n",
       "117          Avery Bradley       6.0       4.7     8.190646  3.490646\n",
       "113     Karl-Anthony Towns      16.5      17.7    14.215646  3.484354\n",
       "126        Wilson Chandler       7.1       5.6     8.981502  3.381502\n",
       "58        Boban Marjanovic      16.6      16.4    13.047286  3.352714"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing unscaled dataframe \n",
    "\n",
    "unscaled = pd.read_csv('data/clean_nba_stats_data_with_PIE.csv')\n",
    "\n",
    "# just extracting just the Player names and unscaled PIE_2017\n",
    "\n",
    "unscaled = unscaled[['Player', 'PIE_2017']]\n",
    "\n",
    "# getting index of test dataframe\n",
    "test_df = df.loc[y_test.index]\n",
    "\n",
    "# concatenating model predictions, error, and unscaled PIE_2017\n",
    "\n",
    "test_df.insert(1,'predictions', e_preds)\n",
    "test_df.insert(1,'diffs', abs(foo.predictions- foo.PIE_2018))\n",
    "test_df.drop(columns='PIE_2017', inplace=True)\n",
    "test_df = foo.merge(unscaled,on=['Player'], how='left')\n",
    "test_df= foo[['Player','PIE_2017', 'PIE_2018', 'predictions', 'diffs']]\n",
    "test_df = foo.sort_values(by='diffs', ascending=False)\n",
    "\n",
    "\n",
    "#Looking at the 20 worst player predictions\n",
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (model is essentially predicting a regression towards the mean, which is \n",
    "# an observable statistical phenomenom, but does not account for individual player growth, \n",
    "# which I was hoping my model could capture.)\n",
    "\n",
    "# for further model evaluation I should run model on unadvanced stats to see how much of \n",
    "# a diffference the advanced stats affected the model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
