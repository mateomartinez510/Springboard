{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSD Audio Classifier\n",
    "##  02. Data Wrangling & Feature Engineering\n",
    "In this notebook we will feature engine the raw audio files into the following formats:\n",
    "\n",
    "    - Mel-Frequency Sprectrograms\n",
    "    - Mel-Frequency Cepstrum Sprectrograms\n",
    "    - Mean Mel-Frequency Cepstrum Coefficients\n",
    "    \n",
    "In this notebook we will also create synthetic data by Randomly Oversampling the Minority Classes, adding Gaussian Noise with pitch augmentation. We will also Randomly Undersample the Majority Classes to create a balanced dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import os\n",
    "import random\n",
    "from random import choices\n",
    "from random import sample\n",
    "matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Mateo/Springboard/FSD50k'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev_info = pd.read_json('data/data/labelled_dev_info.json')\n",
    "eval_info = pd.read_json('data/data/labelled_eval_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>license</th>\n",
       "      <th>uploader</th>\n",
       "      <th>track_num</th>\n",
       "      <th>wav_name</th>\n",
       "      <th>png_name</th>\n",
       "      <th>labels_15</th>\n",
       "      <th>labels_2</th>\n",
       "      <th>labels_4</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RalfHutterWorking.wav</td>\n",
       "      <td>Ralf Hutter from Kraftwerk saying \"Working on ...</td>\n",
       "      <td>[male, voice]</td>\n",
       "      <td>http://creativecommons.org/licenses/by/3.0/</td>\n",
       "      <td>fectoper</td>\n",
       "      <td>63</td>\n",
       "      <td>63.wav</td>\n",
       "      <td>63.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>keyboard-rhymtic.wav</td>\n",
       "      <td>Noise of an average logitech keyboard. Pretty ...</td>\n",
       "      <td>[keyboard, rhythmic, tap, type]</td>\n",
       "      <td>http://creativecommons.org/licenses/by/3.0/</td>\n",
       "      <td>Anton</td>\n",
       "      <td>136</td>\n",
       "      <td>136.wav</td>\n",
       "      <td>136.png</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>keyboard-typing.wav</td>\n",
       "      <td>Noise of an average logitech keyboard. Pretty ...</td>\n",
       "      <td>[computer, environmental-sounds-research, key,...</td>\n",
       "      <td>http://creativecommons.org/licenses/by/3.0/</td>\n",
       "      <td>Anton</td>\n",
       "      <td>137</td>\n",
       "      <td>137.wav</td>\n",
       "      <td>137.png</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>bell.wav</td>\n",
       "      <td>simple *ting* sound</td>\n",
       "      <td>[bell]</td>\n",
       "      <td>http://creativecommons.org/publicdomain/zero/1.0/</td>\n",
       "      <td>Erratic</td>\n",
       "      <td>221</td>\n",
       "      <td>221.wav</td>\n",
       "      <td>221.png</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>BUSSES.aiff</td>\n",
       "      <td>Departing busses\\r\\n at Utrecht Central Railwa...</td>\n",
       "      <td>[bus, depart, drive, station]</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc/3.0/</td>\n",
       "      <td>hanstimm</td>\n",
       "      <td>236</td>\n",
       "      <td>236.wav</td>\n",
       "      <td>236.png</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                        description  \\\n",
       "63   RalfHutterWorking.wav  Ralf Hutter from Kraftwerk saying \"Working on ...   \n",
       "136   keyboard-rhymtic.wav  Noise of an average logitech keyboard. Pretty ...   \n",
       "137    keyboard-typing.wav  Noise of an average logitech keyboard. Pretty ...   \n",
       "221               bell.wav                                simple *ting* sound   \n",
       "236            BUSSES.aiff  Departing busses\\r\\n at Utrecht Central Railwa...   \n",
       "\n",
       "                                                  tags  \\\n",
       "63                                       [male, voice]   \n",
       "136                    [keyboard, rhythmic, tap, type]   \n",
       "137  [computer, environmental-sounds-research, key,...   \n",
       "221                                             [bell]   \n",
       "236                      [bus, depart, drive, station]   \n",
       "\n",
       "                                               license  uploader  track_num  \\\n",
       "63         http://creativecommons.org/licenses/by/3.0/  fectoper         63   \n",
       "136        http://creativecommons.org/licenses/by/3.0/     Anton        136   \n",
       "137        http://creativecommons.org/licenses/by/3.0/     Anton        137   \n",
       "221  http://creativecommons.org/publicdomain/zero/1.0/   Erratic        221   \n",
       "236     http://creativecommons.org/licenses/by-nc/3.0/  hanstimm        236   \n",
       "\n",
       "    wav_name png_name  labels_15  labels_2  labels_4  labels  \n",
       "63    63.wav   63.png          0         0         0       0  \n",
       "136  136.wav  136.png         11         8         3       1  \n",
       "137  137.wav  137.png          8         7         3       1  \n",
       "221  221.wav  221.png          5         3         2       3  \n",
       "236  236.wav  236.png          7         7         3       4  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/Mateo/Springboard/FSD50k/'\n",
    "train_audio_dir = '/Users/Mateo/Springboard/FSD50k/data/FSD50K.dev_audio/'\n",
    "test_audio_dir = '/Users/Mateo/Springboard/FSD50k/data/FSD50K.eval_audio/'\n",
    "# train_wav_names = dev_info.wav_name.to_list()\n",
    "# train_png_names = dev_info.png_name.to_list()\n",
    "# test_wav_names = eval_info.wav_name.to_list()\n",
    "# test_png_names = eval_info.png_name.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Mel-Frequency Spectrograms for Training/Test Data \n",
    "\n",
    "- extracting 128 Mel-Frequency bands as this is the same spectrum as human hearing\n",
    "- padding/trimming audio to 5 seconds for equal dimensions for image analyze (randomly padding with silence to the beginning and end of the shorter audio files)\n",
    "- extracting 216 audio events within the 5 second audio files (23 milliseconds intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Spectorgrams for Training Data\n",
    "\n",
    "# # creating directory\n",
    "# os.chdir(base_dir)\n",
    "# if not os.path.exists('data/train_spectrograms'):\n",
    "#     os.makedirs('data/train_spectrograms')\n",
    "    \n",
    "# # changing into desired directory to save spectrogram images\n",
    "# path = 'data/train_spectrograms'\n",
    "# os.chdir(path)\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# for i in range(len(train_wav_names)):\n",
    "#     file_path = train_audio_dir + train_wav_names[i]\n",
    "#     data, sr = librosa.load(file_path)  # consider using 'kaiser_fast' instead of 'kaiser_best' for faster load time\n",
    "                                          # data, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "#     # trimming to 5 seconds\n",
    "#     # padding with random offset for shorter tracks to 5 seconds\n",
    "\n",
    "#     input_length = 5 * 22050 # 5 seconds * 22050 samples per second (the sample_rate)\n",
    "\n",
    "#     if len(data) > input_length:\n",
    "#         data = data[:input_length]\n",
    "\n",
    "#     elif input_length > len(data):\n",
    "#         max_offset = input_length - len(data)\n",
    "#         offset = np.random.randint(max_offset)\n",
    "#         data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "#     # Fast Fourier Transform, a window for the results image\n",
    "#     n_fft = 2048\n",
    "#     # hop length slides the window (4:1 something er other?)\n",
    "#     hop_length = 512\n",
    "#     # converts audio spectrum into 128 evenly spaced groups based on human hearing\n",
    "#     n_mels = 128\n",
    "\n",
    "#     S = librosa.feature.melspectrogram(data, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "#     S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    \n",
    "#     S_DB = S_DB.astype(np.uint8) #converting from float32 to uint8 (more efficient file format)\n",
    "    \n",
    "#     # NOT SCALING IN THIS ITERATION....\n",
    "# #     # # min-max scale to fit inside 8-bit range\n",
    "\n",
    "# #     img = scale_minmax(S_DB, 0, 255).astype(np.uint8)\n",
    "# #     img = np.flip(img, axis=0) # put low frequencies at the bottom in image\n",
    "# #     img = 255-img # invert. make black==more energy\n",
    "\n",
    "#     skimage.io.imsave(train_png_names[i], S_DB)  # removing .wav suffix with .png \n",
    "#     # to display impage: librosa.display.specshow(img, sr=sr, hop_length=hop_length)\n",
    "    \n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Spectorgrams for Test Data\n",
    "\n",
    "# # creating directory\n",
    "# os.chdir(base_dir)\n",
    "# if not os.path.exists('data/test_spectrograms'):\n",
    "#     os.makedirs('data/test_spectrograms')\n",
    "    \n",
    "# # changing into desired directory to save spectrogram images\n",
    "# path = 'data/test_spectrograms'\n",
    "# os.chdir(path)\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# for i in range(len(test_wav_names)):\n",
    "#     file_path = test_audio_dir + test_wav_names[i]\n",
    "#     # consider using 'kaiser_fast' instead of 'kaiser_best' for faster load time\n",
    "#     data, sr = librosa.load(file_path, res_type='kaiser_fast')  \n",
    "    \n",
    "#     # trimming to 5 seconds\n",
    "#     # padding with random offset for shorter tracks to 5 seconds\n",
    "\n",
    "#     input_length = 5 * 22050 # 5 seconds * 22050 samples per second (the sample_rate)\n",
    "\n",
    "#     if len(data) > input_length:\n",
    "#         data = data[:input_length]\n",
    "\n",
    "#     elif input_length > len(data):\n",
    "#         max_offset = input_length - len(data)\n",
    "#         offset = np.random.randint(max_offset)\n",
    "#         data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "#     # Fast Fourier Transform, a window for the results image\n",
    "#     n_fft = 2048\n",
    "#     # hop length slides the window (4:1 something er other?)\n",
    "#     hop_length = 512\n",
    "#     # converts audio spectrum into 128 evenly spaced groups based on human hearing\n",
    "#     n_mels = 128\n",
    "\n",
    "#     S = librosa.feature.melspectrogram(data, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "#     S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    \n",
    "#     S_DB = S_DB.astype(np.uint8) #converting from float32 to uint8 (more efficient file format)\n",
    "#     skimage.io.imsave(test_wpng_names[i], S_DB)  \n",
    "    \n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Mel-Frequency Cepstrum Spectrogram for Training/Test Data\n",
    "- extracting 32 Mel-Frequency Cepstrum bands to account for tonal frequency bands beyond vocal range (12-20 bands are typical for speech analysis)\n",
    "- padding/trimming audio to 5 seconds for equal dimensions for image analyze\n",
    "- extracting 216 audio events within the 5 second audio files (23 milliseconds intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating Train MFC Spectrograms \n",
    "\n",
    "# # creating directory\n",
    "# os.chdir(base_dir)\n",
    "# if not os.path.exists('data/train_mfcc'):\n",
    "#     os.makedirs('data/train_mfcc')\n",
    "    \n",
    "# # changing into desired directory to save mfcc images\n",
    "# path = 'data/train_mfcc'\n",
    "# os.chdir(path)\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# # intanitating numpy array for Mean MFCC values\n",
    "# num_files = len(train_wav_names)\n",
    "# num_mfcc_features = 32\n",
    "# mfcc_mean_features = np.zeros(shape=(num_files, num_mfcc_features))\n",
    "\n",
    "\n",
    "# for i in range(len(train_wav_names)):\n",
    "#     file_path = train_audio_dir + train_wav_names[i]\n",
    "#     data, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "#     #padding/trimming to 5 seconds with random offset for shorter tracks\n",
    "\n",
    "#     input_length = 5 * 22050\n",
    "\n",
    "#     if len(data) > input_length:\n",
    "#         data = data[:input_length]\n",
    "\n",
    "#     elif input_length > len(data):\n",
    "#         max_offset = input_length - len(data)\n",
    "#         offset = np.random.randint(max_offset)\n",
    "#         data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "#     # extracting mfcc features, using 32 MFCC Bands\n",
    "#     mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=32)\n",
    "    \n",
    "    \n",
    "#     # extracting Mean for each MFCC band\n",
    "#     mfcc_mean = np.mean(mfcc, axis= 1)  # orginally: np.mean(foo.T, axis= 0), but same no?\n",
    "#     # appending mean values to features list\n",
    "#     mfcc_mean_features[i] = mfcc_mean\n",
    "        \n",
    "    \n",
    "#     # converting to uint8 num_type\n",
    "#     mfcc = mfcc.astype(np.uint8)\n",
    "#     skimage.io.imsave(train_png_names[i], mfcc)  # removing .wav suffix with .png \n",
    "\n",
    "    \n",
    "#     # saving numpy array to disk    \n",
    "#     mean_features_filepath = base_dir + 'data/train_mean_mfcc.npz'\n",
    "#     np.savez(mean_features_filepath, mfcc_mean_features)    \n",
    "\n",
    "    \n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Test Data MFCC Spectrogram and Mean MFCC Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating Test MFC Spectrograms \n",
    "\n",
    "# # creating directory\n",
    "# os.chdir(base_dir)\n",
    "# if not os.path.exists('data/test_mfcc'):\n",
    "#     os.makedirs('data/test_mfcc')\n",
    "    \n",
    "# # changing into desired directory to save mfcc images\n",
    "# path = 'data/test_mfcc'\n",
    "# os.chdir(path)\n",
    "\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "\n",
    "# # intanitating numpy array for Mean MFCC values\n",
    "# num_files = len(test_wav_names)\n",
    "# num_mfcc_features = 32\n",
    "# mfcc_mean_features = np.zeros(shape=(num_files, num_mfcc_features))\n",
    "\n",
    "\n",
    "# for i in range(len(test_wav_names)):\n",
    "#     file_path = test_audio_dir + test_wav_names[i]\n",
    "#     data, sr = librosa.load(file_path, res_type = 'kaiser_fast')\n",
    "    \n",
    "#     #padding/trimming to 5 seconds with random offset for shorter tracks\n",
    "\n",
    "#     input_length = 5 * 22050\n",
    "\n",
    "#     if len(data) > input_length:\n",
    "#         data = data[:input_length]\n",
    "\n",
    "#     elif input_length > len(data):\n",
    "#         max_offset = input_length - len(data)\n",
    "#         offset = np.random.randint(max_offset)\n",
    "#         data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "#     # extracting mfcc features\n",
    "#     mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=32)\n",
    "    \n",
    "    \n",
    "#     # extracting Mean for each MFCC band\n",
    "#     mfcc_processed = np.mean(mfcc, axis= 1)  # orginally: np.mean(foo.T, axis= 0), but same no?\n",
    "#     # appending mean values to features list\n",
    "#     mfcc_mean_features[i] = mfcc_processed\n",
    "    \n",
    "    \n",
    "#     # converting to uint8 num_type\n",
    "#     mfcc = mfcc.astype(np.uint8)\n",
    "#     skimage.io.imsave(test_png_names[i], mfcc)  # removing .wav suffix with .png \n",
    "    \n",
    "\n",
    "# # saving numpy array to disk    \n",
    "# mean_features_filepath = base_dir + 'data/test_mean_mfcc.npz'\n",
    "# np.savez(mean_features_filepath, mfcc_mean_features)    \n",
    "\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Balanced Dataframe with Random Over/Under Sampling\n",
    "- there is significant imbalanced classes in the training dataset. We will first create a balanced dataframe by Oversampling the the minority classses and Undersampling the majority classes. We will use Synthetic data for  Randomly Oversampling. We will balance our classes at 5,000, which is the approximate mean of our class value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15105\n",
       "3     9275\n",
       "0     5355\n",
       "4     5118\n",
       "2     3239\n",
       "5     1682\n",
       "7      776\n",
       "6      416\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_num_labels = dev_info[['track_num','labels']].copy()\n",
    "track_num_labels.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersampling majority classes\n",
    "\n",
    "under_samp_0 = sample(set(track_num_labels[track_num_labels.labels == 0].track_num.values), k=5000)\n",
    "under_samp_1 = sample(set(track_num_labels[track_num_labels.labels == 1].track_num.values), k=5000)\n",
    "under_samp_3 = sample(set(track_num_labels[track_num_labels.labels == 3].track_num.values), k=5000)\n",
    "under_samp_4 = sample(set(track_num_labels[track_num_labels.labels == 4].track_num.values), k=5000)\n",
    "\n",
    "# over sampling minority classes\n",
    "\n",
    "over_samp_label_2 = choices(track_num_labels[track_num_labels.labels == 2].track_num.values,k=5000 - dev_info.labels.value_counts().loc[2])\n",
    "over_samp_label_5 = choices(track_num_labels[track_num_labels.labels == 5].track_num.values,k=5000 - dev_info.labels.value_counts().loc[5])\n",
    "over_samp_label_6 = choices(track_num_labels[track_num_labels.labels == 6].track_num.values,k=5000 - dev_info.labels.value_counts().loc[6])\n",
    "over_samp_label_7 = choices(track_num_labels[track_num_labels.labels == 7].track_num.values,k=5000 - dev_info.labels.value_counts().loc[7])\n",
    "\n",
    "full_under_samps = under_samp_0 + under_samp_1 + under_samp_3 + under_samp_4\n",
    "all_over_samps = over_samp_label_2 + over_samp_label_5 + over_samp_label_6 + over_samp_label_7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_labels = track_num_labels[(track_num_labels.labels == 2) | \\\n",
    "                                   (track_num_labels.labels == 5) | \\\n",
    "                                   (track_num_labels.labels == 6) | \\\n",
    "                                   (track_num_labels.labels == 7)   \\\n",
    "                                  ].track_num.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>labels</th>\n",
       "      <th>png_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>2</td>\n",
       "      <td>305.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>344.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>420.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>1729</td>\n",
       "      <td>2</td>\n",
       "      <td>1729.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>1730</td>\n",
       "      <td>2</td>\n",
       "      <td>1730.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      track_num  labels  png_name\n",
       "305         305       2   305.png\n",
       "344         344       2   344.png\n",
       "420         420       2   420.png\n",
       "1729       1729       2  1729.png\n",
       "1730       1730       2  1730.png"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_plus_under_samps = minority_labels + full_under_samps\n",
    "df_under_samps_plus_minority = track_num_labels.loc[minority_plus_under_samps]\n",
    "df_under_samps_plus_minority['png_name'] = df_under_samps_plus_minority['track_num'].apply(lambda x: str(x) + '.png')\n",
    "df_under_samps_plus_minority.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a counter for the repeatedly sampled values to create a unique filename I.D.\n",
    "\n",
    "counter = {}\n",
    "synth_list = []\n",
    "\n",
    "for samp in all_over_samps:\n",
    "    if samp not in counter:\n",
    "        counter[samp] = 0\n",
    "    else:\n",
    "        counter[samp] += 1\n",
    "    synth_list.append(f'synth_{(counter[samp])}_{samp}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>png_name</th>\n",
       "      <th>labels</th>\n",
       "      <th>wav_name</th>\n",
       "      <th>wav_png_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233133</td>\n",
       "      <td>synth_0_233133.png</td>\n",
       "      <td>2</td>\n",
       "      <td>233133.wav</td>\n",
       "      <td>(233133.wav, synth_0_233133.png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391175</td>\n",
       "      <td>synth_0_391175.png</td>\n",
       "      <td>2</td>\n",
       "      <td>391175.wav</td>\n",
       "      <td>(391175.wav, synth_0_391175.png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341178</td>\n",
       "      <td>synth_0_341178.png</td>\n",
       "      <td>2</td>\n",
       "      <td>341178.wav</td>\n",
       "      <td>(341178.wav, synth_0_341178.png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249724</td>\n",
       "      <td>synth_0_249724.png</td>\n",
       "      <td>2</td>\n",
       "      <td>249724.wav</td>\n",
       "      <td>(249724.wav, synth_0_249724.png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141471</td>\n",
       "      <td>synth_0_141471.png</td>\n",
       "      <td>2</td>\n",
       "      <td>141471.wav</td>\n",
       "      <td>(141471.wav, synth_0_141471.png)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_num            png_name  labels    wav_name  \\\n",
       "0    233133  synth_0_233133.png       2  233133.wav   \n",
       "1    391175  synth_0_391175.png       2  391175.wav   \n",
       "2    341178  synth_0_341178.png       2  341178.wav   \n",
       "3    249724  synth_0_249724.png       2  249724.wav   \n",
       "4    141471  synth_0_141471.png       2  141471.wav   \n",
       "\n",
       "                      wav_png_tuple  \n",
       "0  (233133.wav, synth_0_233133.png)  \n",
       "1  (391175.wav, synth_0_391175.png)  \n",
       "2  (341178.wav, synth_0_341178.png)  \n",
       "3  (249724.wav, synth_0_249724.png)  \n",
       "4  (141471.wav, synth_0_141471.png)  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe for just the synthetic data\n",
    "\n",
    "synth_df = pd.DataFrame(data=[all_over_samps, synth_list], columns= all_over_samps,index=['track_num', 'png_name']).T\n",
    "synth_df = synth_df.merge(track_num_labels, how='left', on = 'track_num')\n",
    "synth_df['wav_name'] = synth_df['track_num'].apply(lambda x: str(x) + '.wav')\n",
    "synth_df['wav_png_tuple'] = list(zip(synth_df['wav_name'], synth_df['png_name']))\n",
    "synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>labels</th>\n",
       "      <th>png_name</th>\n",
       "      <th>wav_name</th>\n",
       "      <th>wav_png_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>63.png</td>\n",
       "      <td>63.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>136.png</td>\n",
       "      <td>136.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>137.png</td>\n",
       "      <td>137.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236</td>\n",
       "      <td>4</td>\n",
       "      <td>236.png</td>\n",
       "      <td>236.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237</td>\n",
       "      <td>4</td>\n",
       "      <td>237.png</td>\n",
       "      <td>237.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_num  labels png_name wav_name wav_png_tuple\n",
       "0        63       0   63.png   63.wav           NaN\n",
       "1       136       1  136.png  136.wav           NaN\n",
       "2       137       1  137.png  137.wav           NaN\n",
       "3       236       4  236.png  236.wav           NaN\n",
       "4       237       4  237.png  237.wav           NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe with the synthetic data and our undesampled majority classes\n",
    "\n",
    "full_synth_df = pd.concat(objs=[df_under_samps_plus_minority, synth_df], ignore_index=True)\n",
    "full_synth_df = full_synth_df.sort_values(by='track_num').reset_index(drop=True)\n",
    "full_synth_df['wav_name'] = full_synth_df['track_num'].apply(lambda x: str(x) + '.wav')\n",
    "full_synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not saving anything to disk now!\n",
    "\n",
    "# saving dataframe with the synthetic data and our undesampled majority classes to disk\n",
    "\n",
    "######### full_synth_df.to_json('data/training_plus_synth_df.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Synthetic Audio Files for Mel-Frequency Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/Mateo/Springboard/FSD50k/'\n",
    "train_audio_dir = '/Users/Mateo/Springboard/FSD50k/data/FSD50K.dev_audio/'\n",
    "synth_wav_names = synth_df.wav_name.to_list()\n",
    "synth_png_names = synth_df.png_name.to_list()\n",
    "synth_wav_png_names = synth_df.wav_png_tuple.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # # Synthetic Training Spectrograms \n",
    "\n",
    "# # creating directory\n",
    "# os.chdir(base_dir)\n",
    "# if not os.path.exists('data/synth_spectrograms4'):\n",
    "#     os.makedirs('data/synth_spectrograms4')\n",
    "    \n",
    "# # changing into desired directory to save spectrogram images\n",
    "# path = 'data/synth_spectrograms4'\n",
    "# os.chdir(path)\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# # empty list to append new track names and their corresponding dataframe I.D. key\n",
    "\n",
    "# track_names_id_key = []\n",
    "\n",
    "# for i in range(len(synth_wav_png_names)):\n",
    "#     file_path = train_audio_dir + synth_wav_png_names[i][0]\n",
    "#     data, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "#     # trimming to 5 seconds\n",
    "#     # padding with random offset for shorter tracks to 5 seconds\n",
    "\n",
    "#     input_length = 5 * 22050 # 5 seconds * 22050 samples per second (the sample_rate)\n",
    "\n",
    "#     if len(data) > input_length:\n",
    "#         data = data[:input_length]\n",
    "\n",
    "#     elif input_length > len(data):\n",
    "#         max_offset = input_length - len(data)\n",
    "#         offset = np.random.randint(max_offset)\n",
    "#         data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "\n",
    "#     #########\n",
    "    \n",
    "    \n",
    "#     #  ADD NOISE HERE!!!!\n",
    "#     # shifting pitch and adding gaussian noise\n",
    "\n",
    "#     data_shifted = librosa.effects.pitch_shift(data, sr, n_steps=random.randint(-4,4))\n",
    "#     #Generating noise, with a Gaussian distribution with mean =0 and standard deviation = RMS_required (std of audio signal)\n",
    "#     STD_noise=np.sqrt(np.mean(data_shifted**2)) \n",
    "#     noise=np.random.normal(0, STD_noise, data_shifted.shape[0])  \n",
    "#     # dampening noise by a factor of 25\n",
    "#     noise = noise / 25\n",
    "#     data_plus_noise = data_shifted + noise\n",
    "    \n",
    "#     ########\n",
    "    \n",
    "    \n",
    "#     # Fast Fourier Transform, a window for the results image\n",
    "#     n_fft = 2048\n",
    "#     # hop length slides the window (4:1 something er other?)\n",
    "#     hop_length = 512\n",
    "#     # converts audio spectrum into 128 evenly spaced groups based on human hearing\n",
    "#     n_mels = 128\n",
    "\n",
    "#     S = librosa.feature.melspectrogram(data_plus_noise, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "#     S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "       \n",
    "#     S_DB = S_DB.astype(np.uint8) #converting from float32 to uint8 (more efficient file format)\n",
    "    \n",
    "#     new_file_name = 'synth_' + str(i) +'_id.png'\n",
    "#     track_names_id_key.append((synth_wav_png_names[i], new_file_name))\n",
    "#     skimage.io.imsave(new_file_name, S_DB) \n",
    "    \n",
    "#     # counting loop:\n",
    "#     if i % 3000 == 0:\n",
    "#         print(i)\n",
    "    \n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with New Filename I.D. Keys\n",
    "\n",
    "track_names_id_key_df = pd.DataFrame(track_names_id_key, columns=['wav_png_tuple', 'new_id'])\n",
    "\n",
    "# merging new dataframe to main dataframe\n",
    "synth_df = synth_df.merge(track_names_id_key_df, how='left', on = 'wav_png_tuple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not saving to disk!!!!\n",
    "\n",
    "# # saving dataframe to disk\n",
    "# os.chdir(base_dir)\n",
    "############################ synth_df.to_json('data/synth_df_with_ids.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Synthetic MFC Spectrograms \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "3669.7071709632874\n"
     ]
    }
   ],
   "source": [
    "# # saving Test MFCC Spectrograms and Mean MFCC to disk\n",
    "\n",
    "# # creating directory\n",
    "# os.chdir(base_dir)\n",
    "# if not os.path.exists('data/synth_mfcc4'):\n",
    "#     os.makedirs('data/synth_mfcc4')\n",
    "    \n",
    "# # changing into desired directory to save mfcc images\n",
    "# path = 'data/synth_mfcc4'\n",
    "# os.chdir(path)\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# mfcc_track_id_key = []\n",
    "\n",
    "# for i in range(len(synth_wav_png_names)):\n",
    "#     file_path = train_audio_dir + synth_wav_png_names[i][0]\n",
    "#     data, sr = librosa.load(file_path, res_type = 'kaiser_fast')\n",
    "    \n",
    "#     #padding/trimming to 5 seconds with random offset for shorter tracks\n",
    "\n",
    "#     input_length = 5 * 22050\n",
    "\n",
    "#     if len(data) > input_length:\n",
    "#         data = data[:input_length]\n",
    "\n",
    "#     elif input_length > len(data):\n",
    "#         max_offset = input_length - len(data)\n",
    "#         offset = np.random.randint(max_offset)\n",
    "#         data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "#     #########\n",
    "    \n",
    "    \n",
    "#     #  ADD NOISE HERE!!!!\n",
    "#     # shifting pitch and adding gaussian noise\n",
    "\n",
    "#     data_shifted = librosa.effects.pitch_shift(data, sr, n_steps=random.randint(-4, 4))\n",
    "#     #Generating noise, with a Gaussian distribution with mean =0 and standard deviation = RMS_required (std of audio signal)\n",
    "#     STD_noise=np.sqrt(np.mean(data_shifted**2)) \n",
    "#     noise=np.random.normal(0, STD_noise, data_shifted.shape[0])  \n",
    "#     # dampening noise by a factor of 25\n",
    "#     noise = noise / 25\n",
    "#     data_plus_noise = data_shifted + noise\n",
    "    \n",
    "#     ########\n",
    "    \n",
    "#     # extracting mfcc features\n",
    "#     mfcc = librosa.feature.mfcc(y=data_plus_noise, sr=sr, n_mfcc=32)\n",
    "    \n",
    "#     # converting to uint8 num_type\n",
    "#     mfcc = mfcc.astype(np.uint8)\n",
    "    \n",
    "#     # saving mfcc to disk    \n",
    "#     new_file_name = 'synth_' + str(i) +'_id.png'\n",
    "#     mfcc_track_id_key.append((synth_wav_png_names[i], new_file_name))\n",
    "#     skimage.io.imsave(new_file_name, mfcc) \n",
    "  \n",
    "#     # counting loop:\n",
    "#     if i % 3000 == 0:\n",
    "#         print(i)\n",
    "    \n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with New Filename I.D. Keys\n",
    "mfcc_id_key_df = pd.DataFrame(mfcc_track_id_key, columns=['wav_png_tuple', 'new_mfcc_id'])\n",
    "track_names_id_key_df = pd.DataFrame(track_names_id_key, columns=['wav_png_tuple', 'synth_mfcc_id'])\n",
    "synth_df = synth_df.merge(track_names_id_key_df, how='left', on = 'wav_png_tuple')\n",
    "synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # saving dataframe to disk\n",
    "# os.chdir(base_dir)\n",
    "############################### synth_df.to_json('data/synth_mfcc_ids_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final dataframe with only: Labels, Track Numb,  Track I.D.s\n",
    "\n",
    "synth_df2 = synth_df.copy()\n",
    "synth_df2 = synth_df2[['track_num', 'labels', 'new_id']]\n",
    "synth_df2 = synth_df2.rename(columns={'new_id':'png_name'})\n",
    "train_synth_df = pd.concat([df_under_samps_plus_minority,synth_df2],ignore_index=True)\n",
    "train_synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Dataframe should be used for all modeling notebooks.\n",
    "\n",
    "# os.chdir(base_dir)\n",
    "########################### train_synth_df.to_json('data/train_synth_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_synth_df =pd.read_json('data/train_synth_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>labels</th>\n",
       "      <th>png_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>305</td>\n",
       "      <td>2</td>\n",
       "      <td>305.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>344.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>420.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1729</td>\n",
       "      <td>2</td>\n",
       "      <td>1729.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1730</td>\n",
       "      <td>2</td>\n",
       "      <td>1730.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_num  labels  png_name\n",
       "0        305       2   305.png\n",
       "1        344       2   344.png\n",
       "2        420       2   420.png\n",
       "3       1729       2  1729.png\n",
       "4       1730       2  1730.png"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_synth_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_synth_df.png_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13887, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26113, 3)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under_samps_plus_minority.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [EDIT] Extracting Mean MFCC  Values with Resampled Dataset \n",
    "    - We will extract the Mean MFCC  Values for the new synthetic data as well as the undersampled majority classes to create a new dataframe to use for modeling.\n",
    "\n",
    "\n",
    "#### This needs to be run again (error in last iteration of feature extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_synth_wav_names = full_synth_df.wav_name.to_list()\n",
    "#full_synth_png_names = full_synth_df.png_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_synth_wav_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving Mean MFCC Values to disk\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# intanitating numpy array for Mean MFCC values\n",
    "num_files = len(full_synth_wav_names)\n",
    "num_mfcc_features = 32\n",
    "mfcc_mean_features = np.zeros(shape=(num_files, num_mfcc_features))\n",
    "\n",
    "\n",
    "for i in range(len(full_synth_wav_names)):\n",
    "    file_path = train_audio_dir + full_synth_wav_names[i]\n",
    "    data, sr = librosa.load(file_path, res_type = 'kaiser_fast')\n",
    "    \n",
    "    \n",
    "    #trimming to 5 seconds with random offset for shorter tracks\n",
    "\n",
    "    input_length = 5 * 22050\n",
    "\n",
    "    \n",
    "    #Not padding shorter tracks as silence with throw off Mean Values\n",
    "\n",
    "#     if len(data) > input_length:\n",
    "#         data = data[:input_length]\n",
    "#         pass\n",
    "\n",
    "    if input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    \n",
    "    #  ADD NOISE HERE!!!!\n",
    "    # shifting pitch and adding gaussian noise\n",
    "\n",
    "    data_shifted = librosa.effects.pitch_shift(data, sr, n_steps=random.randint(-4,4))\n",
    "    #Generating noise, with a Gaussian distribution with mean =0 and standard deviation = RMS_required (std of audio signal)\n",
    "    STD_noise=np.sqrt(np.mean(data_shifted**2)) \n",
    "    noise=np.random.normal(0, STD_noise, data_shifted.shape[0])  \n",
    "    # dampening noise by a factor of 25\n",
    "    noise = noise / 25\n",
    "    data_plus_noise = data_shifted + noise\n",
    "    \n",
    "    ########\n",
    "    \n",
    "    # extracting mfcc features\n",
    "    mfcc = librosa.feature.mfcc(y=data_plus_noise, sr=sr, n_mfcc=32)\n",
    "    \n",
    "    \n",
    "    # extracting Mean for each MFCC band\n",
    "    mfcc_processed = np.mean(mfcc, axis= 1) \n",
    "    # appending mean values to features list\n",
    "    mfcc_mean_features[i] = mfcc_processed\n",
    "\n",
    "# saving numpy array to disk    \n",
    "mean_features_filepath = base_dir + 'data/full_training_plus_synth_mean_mfcc.npz'\n",
    "np.savez(mean_features_filepath, mfcc_mean_features)    \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(mfcc_mean_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step: EDA\n",
    "    - In the next notebook we will perform Exploratory Data Analysis on these newly created features and the metadata of the audio files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
