{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household Sounds Capstone\n",
    "##  2. Data Wrangling & Feature Engineering\n",
    "In this notebook we will feature engine the raw audio files into the following formats:\n",
    "\n",
    "    - Mel-Frequency Sprectrograms\n",
    "    - Mel-Frequency Cepstrum Sprectrograms\n",
    "    - Mean Mel-Frequency Cepstrum Coefficients\n",
    "    \n",
    "In this notebook we will also create synthetic data by Randomly Oversampling the Minority Classes, adding Gaussian Noise with pitch augmentation. We will also Randomly Undersample the Majority Classes to create a balanced dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import os\n",
    "import random\n",
    "from random import choices\n",
    "from random import sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev_info = pd.read_json('data/data/labelled_dev_info.json')\n",
    "eval_info = pd.read_json('data/data/labelled_eval_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>license</th>\n",
       "      <th>uploader</th>\n",
       "      <th>track_num</th>\n",
       "      <th>wav_name</th>\n",
       "      <th>png_name</th>\n",
       "      <th>labels_15</th>\n",
       "      <th>labels_2</th>\n",
       "      <th>labels_4</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RalfHutterWorking.wav</td>\n",
       "      <td>Ralf Hutter from Kraftwerk saying \"Working on ...</td>\n",
       "      <td>[male, voice]</td>\n",
       "      <td>http://creativecommons.org/licenses/by/3.0/</td>\n",
       "      <td>fectoper</td>\n",
       "      <td>63</td>\n",
       "      <td>63.wav</td>\n",
       "      <td>63.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>keyboard-rhymtic.wav</td>\n",
       "      <td>Noise of an average logitech keyboard. Pretty ...</td>\n",
       "      <td>[keyboard, rhythmic, tap, type]</td>\n",
       "      <td>http://creativecommons.org/licenses/by/3.0/</td>\n",
       "      <td>Anton</td>\n",
       "      <td>136</td>\n",
       "      <td>136.wav</td>\n",
       "      <td>136.png</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>keyboard-typing.wav</td>\n",
       "      <td>Noise of an average logitech keyboard. Pretty ...</td>\n",
       "      <td>[computer, environmental-sounds-research, key,...</td>\n",
       "      <td>http://creativecommons.org/licenses/by/3.0/</td>\n",
       "      <td>Anton</td>\n",
       "      <td>137</td>\n",
       "      <td>137.wav</td>\n",
       "      <td>137.png</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>bell.wav</td>\n",
       "      <td>simple *ting* sound</td>\n",
       "      <td>[bell]</td>\n",
       "      <td>http://creativecommons.org/publicdomain/zero/1.0/</td>\n",
       "      <td>Erratic</td>\n",
       "      <td>221</td>\n",
       "      <td>221.wav</td>\n",
       "      <td>221.png</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>BUSSES.aiff</td>\n",
       "      <td>Departing busses\\r\\n at Utrecht Central Railwa...</td>\n",
       "      <td>[bus, depart, drive, station]</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc/3.0/</td>\n",
       "      <td>hanstimm</td>\n",
       "      <td>236</td>\n",
       "      <td>236.wav</td>\n",
       "      <td>236.png</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                        description  \\\n",
       "63   RalfHutterWorking.wav  Ralf Hutter from Kraftwerk saying \"Working on ...   \n",
       "136   keyboard-rhymtic.wav  Noise of an average logitech keyboard. Pretty ...   \n",
       "137    keyboard-typing.wav  Noise of an average logitech keyboard. Pretty ...   \n",
       "221               bell.wav                                simple *ting* sound   \n",
       "236            BUSSES.aiff  Departing busses\\r\\n at Utrecht Central Railwa...   \n",
       "\n",
       "                                                  tags  \\\n",
       "63                                       [male, voice]   \n",
       "136                    [keyboard, rhythmic, tap, type]   \n",
       "137  [computer, environmental-sounds-research, key,...   \n",
       "221                                             [bell]   \n",
       "236                      [bus, depart, drive, station]   \n",
       "\n",
       "                                               license  uploader  track_num  \\\n",
       "63         http://creativecommons.org/licenses/by/3.0/  fectoper         63   \n",
       "136        http://creativecommons.org/licenses/by/3.0/     Anton        136   \n",
       "137        http://creativecommons.org/licenses/by/3.0/     Anton        137   \n",
       "221  http://creativecommons.org/publicdomain/zero/1.0/   Erratic        221   \n",
       "236     http://creativecommons.org/licenses/by-nc/3.0/  hanstimm        236   \n",
       "\n",
       "    wav_name png_name  labels_15  labels_2  labels_4  labels  \n",
       "63    63.wav   63.png          0         0         0       0  \n",
       "136  136.wav  136.png         11         8         3       1  \n",
       "137  137.wav  137.png          8         7         3       1  \n",
       "221  221.wav  221.png          5         3         2       3  \n",
       "236  236.wav  236.png          7         7         3       4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/Mateo/Springboard/FSD50k/'\n",
    "train_audio_dir = '/Users/Mateo/Springboard/FSD50k/data/FSD50K.dev_audio/'\n",
    "test_audio_dir = '/Users/Mateo/Springboard/FSD50k/data/FSD50K.eval_audio/'\n",
    "# train_wav_names = dev_info.wav_name.to_list()\n",
    "# train_png_names = dev_info.png_name.to_list()\n",
    "# test_wav_names = eval_info.wav_name.to_list()\n",
    "# test_png_names = eval_info.png_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav_names = eval_info.wav_name.to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Mel-Frequency Spectrograms for Training/Test Data \n",
    "\n",
    "- extracting 128 Mel-Frequency bands as this is the same spectrum as human hearing\n",
    "- padding/trimming audio to 5 seconds for equal dimensions for image analyze (randomly padding with silence to the beginning and end of the shorter audio files)\n",
    "- extracting 216 audio events within the 5 second audio files (23 milliseconds intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Spectrograms for Training Data\n",
    "\n",
    "# creating directory\n",
    "os.chdir(base_dir)\n",
    "if not os.path.exists('data/train_spectrograms'):\n",
    "    os.makedirs('data/train_spectrograms')\n",
    "    \n",
    "# changing into desired directory to save spectrogram images\n",
    "path = 'data/train_spectrograms'\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(len(train_wav_names)):\n",
    "    file_path = train_audio_dir + train_wav_names[i]\n",
    "    data, sr = librosa.load(file_path, res_type='kaiser_fast') #kaiser_fast reduces run time by 50#\n",
    "    \n",
    "    # trimming to 5 seconds\n",
    "    # padding with random offset for shorter tracks to 5 seconds\n",
    "\n",
    "    input_length = 5 * 22050 # 5 seconds * 22050 samples per second (the sample_rate)\n",
    "\n",
    "    if len(data) > input_length:\n",
    "        data = data[:input_length]\n",
    "\n",
    "    elif input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset) # padding with with silence\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "    # Fast Fourier Transform, a window for the resulting image\n",
    "    n_fft = 2048\n",
    "    # hop length detmines the distance to slide the window \n",
    "    hop_length = 512\n",
    "    # converts audio spectrum into 128 evenly spaced spectral ranges based on human hearing\n",
    "    n_mels = 128\n",
    "\n",
    "    # converting audio into Mel-Frequency Spectrogram\n",
    "    S = librosa.feature.melspectrogram(data, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    S_DB = S_DB.astype(np.uint8) #converting from float32 to uint8 (more efficient file format)\n",
    "    \n",
    "    # saving image to directory\n",
    "    skimage.io.imsave(train_png_names[i], S_DB)  # removing .wav suffix with .png \n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Spectrograms for Test Data\n",
    "\n",
    "# creating directory\n",
    "os.chdir(base_dir)\n",
    "if not os.path.exists('data/test_spectrograms'):\n",
    "    os.makedirs('data/test_spectrograms')\n",
    "    \n",
    "# changing into desired directory to save spectrogram images\n",
    "path = 'data/test_spectrograms'\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(len(test_wav_names)):\n",
    "    file_path = test_audio_dir + test_wav_names[i]\n",
    "    # consider using 'kaiser_fast' instead of 'kaiser_best' for faster load time\n",
    "    data, sr = librosa.load(file_path, res_type='kaiser_fast')  \n",
    "    \n",
    "    # trimming to 5 seconds\n",
    "    # padding with random offset for shorter tracks to 5 seconds\n",
    "\n",
    "    input_length = 5 * 22050 # 5 seconds * 22050 samples per second (the sample_rate)\n",
    "\n",
    "    if len(data) > input_length:\n",
    "        data = data[:input_length]\n",
    "\n",
    "    elif input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "    # Fast Fourier Transform, a window for the results image\n",
    "    n_fft = 2048\n",
    "    # hop length slides the window \n",
    "    hop_length = 512\n",
    "    # converts audio spectrum into 128 evenly spaced groups based on human hearing\n",
    "    n_mels = 128\n",
    "\n",
    "    S = librosa.feature.melspectrogram(data, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    \n",
    "    S_DB = S_DB.astype(np.uint8) #converting from float32 to uint8 (more efficient file format)\n",
    "    skimage.io.imsave(test_wpng_names[i], S_DB)  \n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Mel-Frequency Cepstrum Spectrogram for Training/Test Data\n",
    "- extracting 32 Mel-Frequency Cepstrum bands to account for tonal frequency bands beyond vocal range (12-20 bands are typical for speech analysis)\n",
    "- padding/trimming audio to 5 seconds for equal dimensions for image analyze\n",
    "- extracting 216 audio events within the 5 second audio files (23 milliseconds intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train Mel-Frequency Cepstral Coefficient Spectrograms \n",
    "\n",
    "# creating directory\n",
    "os.chdir(base_dir)\n",
    "if not os.path.exists('data/train_mfcc'):\n",
    "    os.makedirs('data/train_mfcc')\n",
    "    \n",
    "# changing into desired directory to save mfcc images\n",
    "path = 'data/train_mfcc'\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# intanitating numpy array for Mean MFCC values\n",
    "num_files = len(train_wav_names)\n",
    "num_mfcc_features = 32\n",
    "mfcc_mean_features = np.zeros(shape=(num_files, num_mfcc_features))\n",
    "\n",
    "\n",
    "for i in range(len(train_wav_names)):\n",
    "    file_path = train_audio_dir + train_wav_names[i]\n",
    "    data, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "    #padding/trimming to 5 seconds with random offset for shorter tracks\n",
    "    input_length = 5 * 22050\n",
    "\n",
    "    if len(data) > input_length:\n",
    "        data = data[:input_length]\n",
    "\n",
    "    elif input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "    # extracting mfcc features, using 32 MFCC Bands\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=32)\n",
    "    \n",
    "    \n",
    "    # extracting Mean for each MFCC band\n",
    "    mfcc_mean = np.mean(mfcc, axis= 1)  \n",
    "    # appending mean values to features list\n",
    "    mfcc_mean_features[i] = mfcc_mean\n",
    "        \n",
    "    \n",
    "    # converting to uint8 num_type\n",
    "    mfcc = mfcc.astype(np.uint8)\n",
    "    skimage.io.imsave(train_png_names[i], mfcc)  # removing .wav suffix with .png \n",
    "\n",
    "    \n",
    "    # saving numpy array to disk    \n",
    "    mean_features_filepath = base_dir + 'data/train_mean_mfcc.npz'\n",
    "    np.savez(mean_features_filepath, mfcc_mean_features)    \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Test Data MFCC Spectrogram and Mean MFCC Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Test MFC Spectrograms \n",
    "\n",
    "# creating directory\n",
    "os.chdir(base_dir)\n",
    "if not os.path.exists('data/test_mfcc'):\n",
    "    os.makedirs('data/test_mfcc')\n",
    "    \n",
    "# changing into desired directory to save mfcc images\n",
    "path = 'data/test_mfcc'\n",
    "os.chdir(path)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# intanitating numpy array for Mean MFCC values\n",
    "num_files = len(test_wav_names)\n",
    "num_mfcc_features = 32\n",
    "mfcc_mean_features = np.zeros(shape=(num_files, num_mfcc_features))\n",
    "\n",
    "for i in range(len(test_wav_names)):\n",
    "    file_path = test_audio_dir + test_wav_names[i]\n",
    "    data, sr = librosa.load(file_path, res_type = 'kaiser_fast')\n",
    "    \n",
    "    #padding/trimming to 5 seconds with random offset for shorter tracks\n",
    "\n",
    "    input_length = 5 * 22050\n",
    "\n",
    "    if len(data) > input_length:\n",
    "        data = data[:input_length]\n",
    "\n",
    "    elif input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "    # extracting mfcc features\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=32)\n",
    "      \n",
    "    # extracting Mean for each MFCC band\n",
    "    mfcc_processed = np.mean(mfcc, axis= 1)  # orginally: np.mean(foo.T, axis= 0), but same no?\n",
    "    # appending mean values to features list\n",
    "    mfcc_mean_features[i] = mfcc_processed\n",
    "      \n",
    "    # converting to uint8 num_type\n",
    "    mfcc = mfcc.astype(np.uint8)\n",
    "    skimage.io.imsave(test_png_names[i], mfcc)  # removing .wav suffix with .png \n",
    "    \n",
    "\n",
    "# saving numpy array to disk    \n",
    "mean_features_filepath = base_dir + 'data/test_mean_mfcc.npz'\n",
    "np.savez(mean_features_filepath, mfcc_mean_features)    \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Balanced Dataframe with Random Over/Under Sampling\n",
    "- there is significant imbalanced classes in the training dataset. We will first create a balanced dataframe by Oversampling the the minority classses and Undersampling the majority classes. We will use Synthetic data for  Randomly Oversampling. We will balance our classes at 5,000, which is the approximate mean of our class value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15105\n",
       "3     9275\n",
       "0     5355\n",
       "4     5118\n",
       "2     3239\n",
       "5     1682\n",
       "7      776\n",
       "6      416\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_num_labels = dev_info[['track_num','labels']].copy()\n",
    "track_num_labels.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersampling majority classes\n",
    "\n",
    "under_samp_0 = sample(set(track_num_labels[track_num_labels.labels == 0].track_num.values), k=5000)\n",
    "under_samp_1 = sample(set(track_num_labels[track_num_labels.labels == 1].track_num.values), k=5000)\n",
    "under_samp_3 = sample(set(track_num_labels[track_num_labels.labels == 3].track_num.values), k=5000)\n",
    "under_samp_4 = sample(set(track_num_labels[track_num_labels.labels == 4].track_num.values), k=5000)\n",
    "\n",
    "# over sampling minority classes\n",
    "\n",
    "over_samp_label_2 = choices(track_num_labels[track_num_labels.labels == 2].track_num.values,k=5000 - dev_info.labels.value_counts().loc[2])\n",
    "over_samp_label_5 = choices(track_num_labels[track_num_labels.labels == 5].track_num.values,k=5000 - dev_info.labels.value_counts().loc[5])\n",
    "over_samp_label_6 = choices(track_num_labels[track_num_labels.labels == 6].track_num.values,k=5000 - dev_info.labels.value_counts().loc[6])\n",
    "over_samp_label_7 = choices(track_num_labels[track_num_labels.labels == 7].track_num.values,k=5000 - dev_info.labels.value_counts().loc[7])\n",
    "\n",
    "# concatenating undersampled data and over sampled data\n",
    "full_under_samps = under_samp_0 + under_samp_1 + under_samp_3 + under_samp_4\n",
    "all_over_samps = over_samp_label_2 + over_samp_label_5 + over_samp_label_6 + over_samp_label_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of tracks to over sample with data augmentation\n",
    "minority_labels = track_num_labels[(track_num_labels.labels == 2) | \\\n",
    "                                   (track_num_labels.labels == 5) | \\\n",
    "                                   (track_num_labels.labels == 6) | \\\n",
    "                                   (track_num_labels.labels == 7)   \\\n",
    "                                  ].track_num.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>labels</th>\n",
       "      <th>png_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>2</td>\n",
       "      <td>305.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>344.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>420.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>1729</td>\n",
       "      <td>2</td>\n",
       "      <td>1729.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>1730</td>\n",
       "      <td>2</td>\n",
       "      <td>1730.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      track_num  labels  png_name\n",
       "305         305       2   305.png\n",
       "344         344       2   344.png\n",
       "420         420       2   420.png\n",
       "1729       1729       2  1729.png\n",
       "1730       1730       2  1730.png"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining all data exluding data that has yet to be augmented\n",
    "minority_plus_under_samps = minority_labels + full_under_samps\n",
    "df_under_samps_plus_minority = track_num_labels.loc[minority_plus_under_samps]\n",
    "df_under_samps_plus_minority['png_name'] = df_under_samps_plus_minority['track_num'].apply(lambda x: str(x) + '.png')\n",
    "df_under_samps_plus_minority.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a counter for the repeatedly sampled values to create a unique filename I.D.\n",
    "\n",
    "counter = {}\n",
    "synth_list = []\n",
    "\n",
    "for samp in all_over_samps:\n",
    "    if samp not in counter:\n",
    "        counter[samp] = 0\n",
    "    else:\n",
    "        counter[samp] += 1\n",
    "    synth_list.append(f'synth_{(counter[samp])}_{samp}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>png_name</th>\n",
       "      <th>labels</th>\n",
       "      <th>wav_name</th>\n",
       "      <th>wav_png_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207465</td>\n",
       "      <td>synth_0_207465.png</td>\n",
       "      <td>2</td>\n",
       "      <td>207465.wav</td>\n",
       "      <td>(207465.wav, synth_0_207465.png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325767</td>\n",
       "      <td>synth_0_325767.png</td>\n",
       "      <td>2</td>\n",
       "      <td>325767.wav</td>\n",
       "      <td>(325767.wav, synth_0_325767.png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77591</td>\n",
       "      <td>synth_0_77591.png</td>\n",
       "      <td>2</td>\n",
       "      <td>77591.wav</td>\n",
       "      <td>(77591.wav, synth_0_77591.png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33561</td>\n",
       "      <td>synth_0_33561.png</td>\n",
       "      <td>2</td>\n",
       "      <td>33561.wav</td>\n",
       "      <td>(33561.wav, synth_0_33561.png)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325475</td>\n",
       "      <td>synth_0_325475.png</td>\n",
       "      <td>2</td>\n",
       "      <td>325475.wav</td>\n",
       "      <td>(325475.wav, synth_0_325475.png)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_num            png_name  labels    wav_name  \\\n",
       "0    207465  synth_0_207465.png       2  207465.wav   \n",
       "1    325767  synth_0_325767.png       2  325767.wav   \n",
       "2     77591   synth_0_77591.png       2   77591.wav   \n",
       "3     33561   synth_0_33561.png       2   33561.wav   \n",
       "4    325475  synth_0_325475.png       2  325475.wav   \n",
       "\n",
       "                      wav_png_tuple  \n",
       "0  (207465.wav, synth_0_207465.png)  \n",
       "1  (325767.wav, synth_0_325767.png)  \n",
       "2    (77591.wav, synth_0_77591.png)  \n",
       "3    (33561.wav, synth_0_33561.png)  \n",
       "4  (325475.wav, synth_0_325475.png)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe for just the synthetic data\n",
    "\n",
    "synth_df = pd.DataFrame(data=[all_over_samps, synth_list], columns= all_over_samps,index=['track_num', 'png_name']).T\n",
    "synth_df = synth_df.merge(track_num_labels, how='left', on = 'track_num')\n",
    "synth_df['wav_name'] = synth_df['track_num'].apply(lambda x: str(x) + '.wav')\n",
    "synth_df['wav_png_tuple'] = list(zip(synth_df['wav_name'], synth_df['png_name']))\n",
    "synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>labels</th>\n",
       "      <th>png_name</th>\n",
       "      <th>wav_name</th>\n",
       "      <th>wav_png_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>63.png</td>\n",
       "      <td>63.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>137.png</td>\n",
       "      <td>137.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>3</td>\n",
       "      <td>221.png</td>\n",
       "      <td>221.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236</td>\n",
       "      <td>4</td>\n",
       "      <td>236.png</td>\n",
       "      <td>236.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237</td>\n",
       "      <td>4</td>\n",
       "      <td>237.png</td>\n",
       "      <td>237.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_num  labels png_name wav_name wav_png_tuple\n",
       "0        63       0   63.png   63.wav           NaN\n",
       "1       137       1  137.png  137.wav           NaN\n",
       "2       221       3  221.png  221.wav           NaN\n",
       "3       236       4  236.png  236.wav           NaN\n",
       "4       237       4  237.png  237.wav           NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe with the synthetic data and our undesampled majority classes\n",
    "\n",
    "full_synth_df = pd.concat(objs=[df_under_samps_plus_minority, synth_df], ignore_index=True)\n",
    "full_synth_df = full_synth_df.sort_values(by='track_num').reset_index(drop=True)\n",
    "full_synth_df['wav_name'] = full_synth_df['track_num'].apply(lambda x: str(x) + '.wav')\n",
    "full_synth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Synthetic Audio Files for Mel-Frequency Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/Mateo/Springboard/FSD50k/'\n",
    "train_audio_dir = '/Users/Mateo/Springboard/FSD50k/data/FSD50K.dev_audio/'\n",
    "synth_wav_names = synth_df.wav_name.to_list()\n",
    "synth_png_names = synth_df.png_name.to_list()\n",
    "synth_wav_png_names = synth_df.wav_png_tuple.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num audio files processeed: 0\n",
      "Num audio files processeed: 1000\n",
      "Num audio files processeed: 2000\n",
      "Num audio files processeed: 3000\n",
      "Num audio files processeed: 4000\n",
      "Num audio files processeed: 5000\n",
      "Num audio files processeed: 6000\n",
      "Num audio files processeed: 7000\n",
      "Num audio files processeed: 8000\n",
      "Num audio files processeed: 9000\n",
      "Num audio files processeed: 10000\n",
      "Num audio files processeed: 11000\n",
      "Num audio files processeed: 12000\n",
      "Num audio files processeed: 13000\n",
      "4931.246097326279\n"
     ]
    }
   ],
   "source": [
    "# # Synthetic Training Spectrograms \n",
    "\n",
    "# creating directory\n",
    "os.chdir(base_dir)\n",
    "if not os.path.exists('data/synth_spectrograms5'):\n",
    "    os.makedirs('data/synth_spectrograms5')\n",
    "    \n",
    "# changing into desired directory to save spectrogram images\n",
    "path = 'data/synth_spectrograms5'\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# empty list to append new track names and their corresponding dataframe I.D. key\n",
    "\n",
    "track_names_id_key = []\n",
    "\n",
    "for i in range(len(synth_wav_png_names)):\n",
    "    file_path = train_audio_dir + synth_wav_png_names[i][0]\n",
    "    data, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "\n",
    "    # shifting pitch and adding gaussian noise\n",
    "    data = librosa.effects.pitch_shift(data, sr, n_steps=random.randint(-4,4), bins_per_octave=24)\n",
    "    #Generating noise, with a Gaussian distribution with mean =0 and standard deviation = RMS_required (std of audio signal)\n",
    "    STD_noise=np.sqrt(np.mean(data**2)) \n",
    "    noise=np.random.normal(0, STD_noise, data.shape[0])  \n",
    "    # dampening noise by a factor of 25\n",
    "    noise = noise / 25\n",
    "    data = data + noise\n",
    "\n",
    "    # trimming to 5 seconds and padding with random offset for shorter tracks to 5 seconds\n",
    "    input_length = 5 * 22050 # 5 seconds * 22050 samples per second (the sample_rate)\n",
    "\n",
    "    if len(data) > input_length:\n",
    "        data = data[:input_length]\n",
    "\n",
    "    elif input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "\n",
    "    # Fast Fourier Transform, a window for the results image\n",
    "    n_fft = 2048\n",
    "    # hop length slides the window \n",
    "    hop_length = 512\n",
    "    # converts audio spectrum into 128 evenly spaced groups based on human hearing\n",
    "    n_mels = 128\n",
    "\n",
    "    S = librosa.feature.melspectrogram(data, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "       \n",
    "    S_DB = S_DB.astype(np.uint8) #converting from float32 to uint8 (more efficient file format)\n",
    "    \n",
    "    new_file_name = 'synth2_' + str(i) +'_id.png'\n",
    "    track_names_id_key.append((synth_wav_png_names[i], new_file_name))\n",
    "    skimage.io.imsave(new_file_name, S_DB) \n",
    "    \n",
    "    # counting loop:\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Num audio files processeed:\", i)\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with New Filename I.D. Keys\n",
    "track_names_id_key_df = pd.DataFrame(track_names_id_key, columns=['wav_png_tuple', 'synth_id'])\n",
    "\n",
    "# merging new dataframe to main dataframe\n",
    "synth_df = synth_df.merge(track_names_id_key_df, how='left', on = 'wav_png_tuple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>png_name</th>\n",
       "      <th>labels</th>\n",
       "      <th>wav_name</th>\n",
       "      <th>wav_png_tuple</th>\n",
       "      <th>synth_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207465</td>\n",
       "      <td>synth_0_207465.png</td>\n",
       "      <td>2</td>\n",
       "      <td>207465.wav</td>\n",
       "      <td>(207465.wav, synth_0_207465.png)</td>\n",
       "      <td>synth2_0_id.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325767</td>\n",
       "      <td>synth_0_325767.png</td>\n",
       "      <td>2</td>\n",
       "      <td>325767.wav</td>\n",
       "      <td>(325767.wav, synth_0_325767.png)</td>\n",
       "      <td>synth2_1_id.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77591</td>\n",
       "      <td>synth_0_77591.png</td>\n",
       "      <td>2</td>\n",
       "      <td>77591.wav</td>\n",
       "      <td>(77591.wav, synth_0_77591.png)</td>\n",
       "      <td>synth2_2_id.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33561</td>\n",
       "      <td>synth_0_33561.png</td>\n",
       "      <td>2</td>\n",
       "      <td>33561.wav</td>\n",
       "      <td>(33561.wav, synth_0_33561.png)</td>\n",
       "      <td>synth2_3_id.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325475</td>\n",
       "      <td>synth_0_325475.png</td>\n",
       "      <td>2</td>\n",
       "      <td>325475.wav</td>\n",
       "      <td>(325475.wav, synth_0_325475.png)</td>\n",
       "      <td>synth2_4_id.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_num            png_name  labels    wav_name  \\\n",
       "0    207465  synth_0_207465.png       2  207465.wav   \n",
       "1    325767  synth_0_325767.png       2  325767.wav   \n",
       "2     77591   synth_0_77591.png       2   77591.wav   \n",
       "3     33561   synth_0_33561.png       2   33561.wav   \n",
       "4    325475  synth_0_325475.png       2  325475.wav   \n",
       "\n",
       "                      wav_png_tuple         synth_id  \n",
       "0  (207465.wav, synth_0_207465.png)  synth2_0_id.png  \n",
       "1  (325767.wav, synth_0_325767.png)  synth2_1_id.png  \n",
       "2    (77591.wav, synth_0_77591.png)  synth2_2_id.png  \n",
       "3    (33561.wav, synth_0_33561.png)  synth2_3_id.png  \n",
       "4  (325475.wav, synth_0_325475.png)  synth2_4_id.png  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataframe to disk\n",
    "os.chdir(base_dir)\n",
    "synth_df.to_json('data/spectrogram_synth_df2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Synthetic MFC Spectrograms \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop iteration: 0\n",
      "loop iteration: 1000\n",
      "loop iteration: 2000\n",
      "loop iteration: 3000\n",
      "loop iteration: 4000\n",
      "loop iteration: 5000\n",
      "loop iteration: 6000\n",
      "loop iteration: 7000\n",
      "loop iteration: 8000\n",
      "loop iteration: 9000\n",
      "loop iteration: 10000\n",
      "loop iteration: 11000\n",
      "loop iteration: 12000\n",
      "loop iteration: 13000\n",
      "4628.532048940659\n"
     ]
    }
   ],
   "source": [
    "# saving Test MFCC Spectrograms and Mean MFCC to disk\n",
    "\n",
    "# creating directory\n",
    "os.chdir(base_dir)\n",
    "if not os.path.exists('data/synth_mfcc5'):\n",
    "    os.makedirs('data/synth_mfcc5')\n",
    "    \n",
    "# changing into desired directory to save mfcc images\n",
    "path = 'data/synth_mfcc5'\n",
    "os.chdir(path)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "mfcc_track_id_key = []\n",
    "\n",
    "for i in range(len(synth_wav_png_names)):\n",
    "    file_path = train_audio_dir + synth_wav_png_names[i][0]\n",
    "    data, sr = librosa.load(file_path, res_type = 'kaiser_fast')\n",
    "    \n",
    "#   shifting pitch and adding gaussian noise\n",
    "    data = librosa.effects.pitch_shift(data, sr, n_steps=random.randint(-4,4), bins_per_octave=24)\n",
    "    #Generating noise, with a Gaussian distribution with mean =0 and standard deviation = RMS_required (std of audio signal)\n",
    "    STD_noise=np.sqrt(np.mean(data**2)) \n",
    "    noise=np.random.normal(0, STD_noise, data.shape[0])  \n",
    "    # dampening noise by a factor of 25\n",
    "    noise = noise / 25\n",
    "    data = data + noise\n",
    "\n",
    "    input_length = 5 * 22050 # 5 seconds * 22050 samples per second (the sample_rate)\n",
    "\n",
    "    if len(data) > input_length:\n",
    "        data = data[:input_length]\n",
    "\n",
    "    elif input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=32)\n",
    "    mfcc = mfcc.astype(np.uint8)\n",
    "    new_file_name = 'synth2_' + str(i) +'_id.png'\n",
    "    mfcc_track_id_key.append((synth_wav_png_names[i], new_file_name))\n",
    "    skimage.io.imsave(new_file_name, mfcc) \n",
    "  \n",
    "    if i % 1000 == 0:\n",
    "        print(\"loop iteration:\", i)\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>png_name</th>\n",
       "      <th>labels</th>\n",
       "      <th>wav_name</th>\n",
       "      <th>wav_png_tuple</th>\n",
       "      <th>synth_id</th>\n",
       "      <th>synth_mfcc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207465</td>\n",
       "      <td>synth_0_207465.png</td>\n",
       "      <td>2</td>\n",
       "      <td>207465.wav</td>\n",
       "      <td>(207465.wav, synth_0_207465.png)</td>\n",
       "      <td>synth2_0_id.png</td>\n",
       "      <td>synth2_0_id.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325767</td>\n",
       "      <td>synth_0_325767.png</td>\n",
       "      <td>2</td>\n",
       "      <td>325767.wav</td>\n",
       "      <td>(325767.wav, synth_0_325767.png)</td>\n",
       "      <td>synth2_1_id.png</td>\n",
       "      <td>synth2_1_id.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77591</td>\n",
       "      <td>synth_0_77591.png</td>\n",
       "      <td>2</td>\n",
       "      <td>77591.wav</td>\n",
       "      <td>(77591.wav, synth_0_77591.png)</td>\n",
       "      <td>synth2_2_id.png</td>\n",
       "      <td>synth2_2_id.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33561</td>\n",
       "      <td>synth_0_33561.png</td>\n",
       "      <td>2</td>\n",
       "      <td>33561.wav</td>\n",
       "      <td>(33561.wav, synth_0_33561.png)</td>\n",
       "      <td>synth2_3_id.png</td>\n",
       "      <td>synth2_3_id.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325475</td>\n",
       "      <td>synth_0_325475.png</td>\n",
       "      <td>2</td>\n",
       "      <td>325475.wav</td>\n",
       "      <td>(325475.wav, synth_0_325475.png)</td>\n",
       "      <td>synth2_4_id.png</td>\n",
       "      <td>synth2_4_id.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_num            png_name  labels    wav_name  \\\n",
       "0    207465  synth_0_207465.png       2  207465.wav   \n",
       "1    325767  synth_0_325767.png       2  325767.wav   \n",
       "2     77591   synth_0_77591.png       2   77591.wav   \n",
       "3     33561   synth_0_33561.png       2   33561.wav   \n",
       "4    325475  synth_0_325475.png       2  325475.wav   \n",
       "\n",
       "                      wav_png_tuple         synth_id    synth_mfcc_id  \n",
       "0  (207465.wav, synth_0_207465.png)  synth2_0_id.png  synth2_0_id.png  \n",
       "1  (325767.wav, synth_0_325767.png)  synth2_1_id.png  synth2_1_id.png  \n",
       "2    (77591.wav, synth_0_77591.png)  synth2_2_id.png  synth2_2_id.png  \n",
       "3    (33561.wav, synth_0_33561.png)  synth2_3_id.png  synth2_3_id.png  \n",
       "4  (325475.wav, synth_0_325475.png)  synth2_4_id.png  synth2_4_id.png  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding column with New Filename I.D. Keys\n",
    "mfcc_id_key_df = pd.DataFrame(mfcc_track_id_key, columns=['wav_png_tuple', 'new_mfcc_id'])\n",
    "track_names_id_key_df = pd.DataFrame(track_names_id_key, columns=['wav_png_tuple', 'synth_mfcc_id'])\n",
    "synth_df = synth_df.merge(track_names_id_key_df, how='left', on = 'wav_png_tuple')\n",
    "synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataframe to disk\n",
    "os.chdir(base_dir)\n",
    "synth_df.to_json('data/synth_mfcc_df2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_num</th>\n",
       "      <th>labels</th>\n",
       "      <th>png_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>305</td>\n",
       "      <td>2</td>\n",
       "      <td>305.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>344.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>420.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1729</td>\n",
       "      <td>2</td>\n",
       "      <td>1729.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1730</td>\n",
       "      <td>2</td>\n",
       "      <td>1730.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_num  labels  png_name\n",
       "0       305       2   305.png\n",
       "1       344       2   344.png\n",
       "2       420       2   420.png\n",
       "3      1729       2  1729.png\n",
       "4      1730       2  1730.png"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving final dataframe with only: Labels, Track Numb,  Track I.D.s\n",
    "\n",
    "synth_df2 = synth_df.copy()\n",
    "synth_df2 = synth_df2[['track_num', 'labels', 'synth_id']]\n",
    "synth_df2 = synth_df2.rename(columns={'synth_id':'png_name'})\n",
    "train_synth_df = pd.concat([df_under_samps_plus_minority,synth_df2],ignore_index=True)\n",
    "train_synth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Dataframe should be used for all modeling notebooks.\n",
    "os.chdir(base_dir)\n",
    "train_synth_df.to_json('data/dev_info_resamp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Mean MFCC  Values with Augmentation for Resampled Train and Test Data \n",
    "- Extracting the Mean MFCC Values for the new synthetic data as well as the undersampled majority classes to create a new dataframe to use for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Resampled Training Data MFCC Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_synth_df['wav_name'] = train_synth_df['track_num'].apply(lambda x: str(x) + '.wav')\n",
    "train_synth_wav_names = train_synth_df.wav_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop iteration: 0\n",
      "loop iteration: 1000\n",
      "loop iteration: 2000\n",
      "loop iteration: 3000\n",
      "loop iteration: 4000\n",
      "loop iteration: 5000\n",
      "loop iteration: 6000\n",
      "loop iteration: 7000\n",
      "loop iteration: 8000\n",
      "loop iteration: 9000\n",
      "loop iteration: 10000\n",
      "loop iteration: 11000\n",
      "loop iteration: 12000\n",
      "loop iteration: 13000\n",
      "loop iteration: 14000\n",
      "loop iteration: 15000\n",
      "loop iteration: 16000\n",
      "loop iteration: 17000\n",
      "loop iteration: 18000\n",
      "loop iteration: 19000\n",
      "loop iteration: 20000\n",
      "loop iteration: 21000\n",
      "loop iteration: 22000\n",
      "loop iteration: 23000\n",
      "loop iteration: 24000\n",
      "loop iteration: 25000\n",
      "loop iteration: 26000\n",
      "loop iteration: 27000\n",
      "loop iteration: 28000\n",
      "loop iteration: 29000\n",
      "loop iteration: 30000\n",
      "loop iteration: 31000\n",
      "loop iteration: 32000\n",
      "loop iteration: 33000\n",
      "loop iteration: 34000\n",
      "loop iteration: 35000\n",
      "loop iteration: 36000\n",
      "loop iteration: 37000\n",
      "loop iteration: 38000\n",
      "loop iteration: 39000\n",
      "20007.291143894196\n",
      "(40000, 32)\n"
     ]
    }
   ],
   "source": [
    "# saving Mean MFCC Values to disk\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# intanitating numpy array for Mean MFCC values\n",
    "num_files = len(train_synth_wav_names)\n",
    "num_mfcc_features = 32\n",
    "mfcc_mean_features = np.zeros(shape=(num_files, num_mfcc_features))\n",
    "\n",
    "\n",
    "for i in range(len(train_synth_wav_names)):\n",
    "    file_path = train_audio_dir + train_synth_wav_names[i]\n",
    "    data, sr = librosa.load(file_path, res_type = 'kaiser_fast')\n",
    "    \n",
    "    input_length = 5 * 22050\n",
    "    #Not padding shorter tracks as silence with throw off mean values, still trimming longer tracks\n",
    "    if input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "    # shifting pitch and adding gaussian noise\n",
    "\n",
    "    data_shifted = librosa.effects.pitch_shift(data, sr, n_steps=random.randint(-4,4), bins_per_octave=24)\n",
    "    #Generating noise, with a Gaussian distribution with mean =0 and standard deviation = RMS_required (std of audio signal)\n",
    "    STD_noise=np.sqrt(np.mean(data_shifted**2)) \n",
    "    noise=np.random.normal(0, STD_noise, data_shifted.shape[0])  \n",
    "    # dampening noise by a factor of 25\n",
    "    noise = noise / 25\n",
    "    data_plus_noise = data_shifted + noise\n",
    "\n",
    "    # extracting mfcc features\n",
    "    mfcc = librosa.feature.mfcc(y=data_plus_noise, sr=sr, n_mfcc=32)  \n",
    "    # extracting Mean for each MFCC band\n",
    "    mfcc_processed = np.mean(mfcc, axis= 1) \n",
    "    # appending mean values to features list\n",
    "    mfcc_mean_features[i] = mfcc_processed\n",
    "\n",
    "    \n",
    "    # loop counter:\n",
    "    if i % 1000 == 0:\n",
    "        print(\"loop iteration:\", i)    \n",
    "    \n",
    "# saving numpy array to disk    \n",
    "mean_features_filepath = base_dir + 'data/train_resamp_mean_mfcc_values.npz'\n",
    "np.savez(mean_features_filepath, mfcc_mean_features)    \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(mfcc_mean_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Test Data MFCC Mean Values (REDONE: matching noise addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop iteration: 0\n",
      "loop iteration: 1000\n",
      "loop iteration: 2000\n",
      "loop iteration: 3000\n",
      "loop iteration: 4000\n",
      "loop iteration: 5000\n",
      "loop iteration: 6000\n",
      "loop iteration: 7000\n",
      "loop iteration: 8000\n",
      "loop iteration: 9000\n",
      "loop iteration: 10000\n",
      "1098.048721075058\n",
      "(10231, 32)\n"
     ]
    }
   ],
   "source": [
    "# saving Augmented Test Data MFCC Mean Values to disk\n",
    "start = time.time()\n",
    "\n",
    "# intanitating numpy array for Mean MFCC values\n",
    "num_files = len(test_wav_names)\n",
    "num_mfcc_features = 32\n",
    "mfcc_mean_features = np.zeros(shape=(num_files, num_mfcc_features))\n",
    "\n",
    "\n",
    "for i in range(len(test_wav_names)):\n",
    "    file_path = test_audio_dir + test_wav_names[i]\n",
    "    data, sr = librosa.load(file_path, res_type = 'kaiser_fast')\n",
    "    \n",
    "    input_length = 5 * 22050\n",
    "    #Not padding shorter tracks as silence with throw off Mean Values\n",
    "    if input_length > len(data):\n",
    "        max_offset = input_length - len(data)\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "    # not shifting pitch for test data\n",
    "    # adding gaussian noise to have analogous feature engineering\n",
    "\n",
    "    STD_noise=np.sqrt(np.mean(data**2)) \n",
    "    noise=np.random.normal(0, STD_noise, data.shape[0])  \n",
    "    # dampening noise by a factor of 25\n",
    "    noise = noise / 25\n",
    "    data = data + noise\n",
    "\n",
    "    # extracting mfcc features\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=32)\n",
    "    \n",
    "    # extracting Mean for each MFCC band\n",
    "    mfcc_processed = np.mean(mfcc, axis= 1) \n",
    "    # appending mean values to features list\n",
    "    mfcc_mean_features[i] = mfcc_processed\n",
    "    \n",
    "    # loop counter:\n",
    "    if i % 1000 == 0:\n",
    "        print(\"loop iteration:\", i)   \n",
    "        \n",
    "# saving numpy array to disk    \n",
    "mean_features_filepath = base_dir + 'data/test_augmented_mean_mfcc_values.npz'\n",
    "np.savez(mean_features_filepath, mfcc_mean_features)    \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(mfcc_mean_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step: EDA\n",
    "- In the next notebook we will perform Exploratory Data Analysis on these newly created features and the metadata of the audio files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
